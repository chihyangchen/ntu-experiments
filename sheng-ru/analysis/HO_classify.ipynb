{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import swifter\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import copy\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HO Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mi_ho(f):\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"Timestamp\"] = df[\"Timestamp\"].swifter.apply(lambda x: pd.to_datetime(x) + dt.timedelta(hours=8)) \n",
    "    nr_pci = 'O'\n",
    "    scells = []\n",
    "\n",
    "    def NR_OTA(idx):\n",
    "\n",
    "        if df[\"type_id\"].iloc[idx] == \"5G_NR_RRC_OTA_Packet\": return True\n",
    "        else: return False\n",
    "    \n",
    "    def LTE_SERV_INFO(idx):\n",
    "\n",
    "        if df[\"type_id\"].iloc[idx] == \"LTE_RRC_Serv_Cell_Info\": return True\n",
    "        else: return False\n",
    "    \n",
    "    def find_1st_after(start_idx, target, look_after=1):\n",
    "        for j in range(start_idx, len(df)):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "                continue\n",
    "            if (t_ - t).total_seconds() > look_after:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_1st_before(start_idx, target, look_before=1):\n",
    "        for j in range(start_idx, -1, -1):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "                continue\n",
    "            if (t - t_).total_seconds() > look_before:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_1st_before_with_special_value(start_idx, target, target_value, look_before=1):\n",
    "        for j in range(start_idx, -1, -1):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "                continue\n",
    "            if (t - t_).total_seconds() > look_before:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] in [target_value] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_in_D_exact(targets):\n",
    "\n",
    "        l = []\n",
    "        # In l : (second, ho_type)\n",
    "        for target in targets:\n",
    "            for ho in D[target]:\n",
    "                l.append(((t - ho.start).total_seconds(), target))\n",
    "\n",
    "        if len(l) != 0:\n",
    "            for x in l:\n",
    "                if (x[0]== 0):\n",
    "                    return x[1]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def find_in_D_first_before(targets, look_before=1):\n",
    "\n",
    "        l = []\n",
    "        # In l : (second, ho_type)\n",
    "        for target in targets:\n",
    "            for ho in D[target]:\n",
    "                l.append(((t - ho.end).total_seconds(), target, ho))\n",
    "\n",
    "        if len(l) != 0:\n",
    "            closest = min(filter(lambda x: x[0] > 0, l), key=lambda x: x[0])\n",
    "            if 0 <= closest[0] < look_before:\n",
    "                return closest[1], closest[2]\n",
    "        \n",
    "        return None, None\n",
    "\n",
    "    HO = namedtuple('HO',['start', 'end', 'others', 'trans'], defaults=[None,None,'',''])\n",
    "    \n",
    "    D = {\n",
    "        'Conn_Rel':[], \n",
    "        'Conn_Req':[], # Setup\n",
    "        'LTE_HO': [], # LTE -> newLTE\n",
    "        'MN_HO': [], # LTE + NR -> newLTE + NR\n",
    "        'MN_HO_to_eNB': [], # LTE + NR -> newLTE\n",
    "        'SN_setup': [], # LTE -> LTE + NR => NR setup\n",
    "        'SN_Rel': [], # LTE + NR -> LTE\n",
    "        'SN_HO': [], # LTE + NR -> LTE + newNR  \n",
    "        'RLF_II': [],\n",
    "        'RLF_III': [],\n",
    "        'SCG_RLF': [],\n",
    "        'Add_SCell': [],\n",
    "        }\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # Pass NR RRC packet. In NSA mode, LTE RRC packet include NR packet message.\n",
    "        if NR_OTA(i) or LTE_SERV_INFO(i):\n",
    "            continue\n",
    "\n",
    "        try: lte_pci, lte_earfcn\n",
    "        except: \n",
    "            lte_pci = df[\"PCI\"].iloc[i]\n",
    "            lte_earfcn = int(df[\"Freq\"].iloc[i])\n",
    "\n",
    "        others = ''\n",
    "        t = df[\"Timestamp\"].iloc[i]\n",
    "\n",
    "        if df[\"rrcConnectionRelease\"].iloc[i] == 1:\n",
    "            D['Conn_Rel'].append(HO(start=t))\n",
    "            nr_pci = 'O'\n",
    "\n",
    "        if df[\"rrcConnectionRequest\"].iloc[i] == 1:\n",
    "            \n",
    "            # Define end of rrcConnectionRequest to be rrcConnectionReconfigurationComplete or securityModeComplete.\n",
    "            a = find_1st_after(i, 'rrcConnectionReconfigurationComplete',look_after=2)[0]\n",
    "            b = find_1st_after(i, 'securityModeComplete',look_after=2)[0]\n",
    "        \n",
    "            if a is None and b is None: end = None\n",
    "            elif a is None and b is not None: end = b\n",
    "            elif a is not None and b is None: end = a \n",
    "            else: end = a if a > b else b\n",
    "            \n",
    "            _, idx = find_1st_after(i, 'ueCapabilityInformation',look_after=1)\n",
    "            if idx is not None:\n",
    "                sup_band = df['bandEUTRA'].iloc[idx]\n",
    "                others += f' supported band: {sup_band}.' \n",
    "\n",
    "            serv_cell, serv_freq = df[\"PCI\"].iloc[i], int(df[\"Freq\"].iloc[i])\n",
    "            trans = f'({lte_pci}, {lte_earfcn}) -> ({serv_cell}, {serv_freq})'\n",
    "            \n",
    "            # Check if caused by RLF III.\n",
    "            a, idx = find_1st_before(i, 'rrcConnectionReestablishmentReject', look_before=1)\n",
    "            if a is not None:\n",
    "                others += ' After RLF III.'\n",
    "\n",
    "            D['Conn_Req'].append(HO(start=t,end=end,trans=trans, others=others))\n",
    "\n",
    "            nr_pci = 'O'\n",
    "            lte_pci = serv_cell\n",
    "            lte_earfcn = serv_freq\n",
    "            \n",
    "        if df[\"lte-rrc.t304\"].iloc[i] == 1:\n",
    "            \n",
    "            end, _ = find_1st_after(i, 'rrcConnectionReconfigurationComplete')\n",
    "            serv_cell, target_cell = df[\"PCI\"].iloc[i], int(df['lte_targetPhysCellId'].iloc[i])\n",
    "            serv_freq, target_freq = int(df[\"Freq\"].iloc[i]), int(df['dl-CarrierFreq'].iloc[i])\n",
    "\n",
    "            lte_pci = target_cell\n",
    "            lte_earfcn = target_freq\n",
    "\n",
    "            if df[\"SCellToAddMod-r10\"].iloc[i] == 1:\n",
    "                n =len(str(df[\"SCellIndex-r10.1\"].iloc[i]).split('@'))\n",
    "                others += f' Set up {n} SCell.'\n",
    "            else:\n",
    "                scells = []\n",
    "            \n",
    "            if serv_freq != target_freq:\n",
    "                a,b = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 1)\n",
    "                others += \" Inter frequency HO.\"\n",
    "                if a is not None:\n",
    "                    others += \" Near after RLF.\"\n",
    "                \n",
    "            if df[\"nr-rrc.t304\"].iloc[i] == 1 and df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "                    a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 2)\n",
    "                    \n",
    "                    if a is not None:\n",
    "\n",
    "                        ho_type, ho = find_in_D_first_before(['RLF_II', 'RLF_III'], 2)\n",
    "                        others += f' Near after RLF of trans: {ho.trans}.'\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        ho_type, _ = find_in_D_first_before(['MN_HO_to_eNB', 'SN_Rel'], 2)\n",
    "                        if ho_type is not None:\n",
    "                            others += f' Near after {ho_type}.'\n",
    "\n",
    "                    ori_serv = nr_pci\n",
    "                    nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "                    trans = f'({serv_cell}, {serv_freq}) | {ori_serv} -> {nr_pci}'\n",
    "                    D['SN_setup'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "                    trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {nr_pci}'\n",
    "                    D['MN_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "            else:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "                    a, b = find_1st_before(i, \"scgFailureInformationNR-r15\")\n",
    "                    if a is not None:\n",
    "                        others += \" Caused by scg-failure.\"\n",
    "                    \n",
    "                    orig_serv = nr_pci\n",
    "                    nr_pci = 'O'\n",
    "                    trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                    D['SN_Rel'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    a, _ = find_1st_before(i,\"rrcConnectionSetup\",3)\n",
    "                    if a is not None:\n",
    "                        others += ' Near After connection setup.'\n",
    "                    if nr_pci == 'O':\n",
    "                        trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {nr_pci}'\n",
    "                        D['LTE_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "                    else:\n",
    "                        orig_serv = nr_pci\n",
    "                        nr_pci = 'O'\n",
    "                        trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                        D['MN_HO_to_eNB'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "\n",
    "        if df[\"nr-rrc.t304\"].iloc[i] == 1 and not df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "\n",
    "            end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "        \n",
    "            serv_cell, serv_freq = df[\"PCI\"].iloc[i], int(df[\"Freq\"].iloc[i])\n",
    "            orig_serv = nr_pci\n",
    "            nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "            trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "            D['SN_HO'].append(HO(start=t,end=end,trans=trans))\n",
    "\n",
    "\n",
    "        if df[\"rrcConnectionReestablishmentRequest\"].iloc[i] == 1:\n",
    "\n",
    "            end1, _ = find_1st_after(i, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "            b, _ = find_1st_after(i, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "            end2, _ = find_1st_after(i, 'securityModeComplete',look_after=3)\n",
    "\n",
    "            others += ' ' + df[\"reestablishmentCause\"].iloc[i] + '.'\n",
    "            scells = []\n",
    "\n",
    "            c, _ = find_1st_before(i, 'scgFailureInformationNR-r15', 1)\n",
    "            if c != None:\n",
    "                others  += ' caused by scgfailure.'\n",
    "                \n",
    "            serv_cell, rlf_cell = df[\"PCI\"].iloc[i], int(df['physCellId.3'].iloc[i])\n",
    "            serv_freq = int(df['Freq'].iloc[i])\n",
    "            \n",
    "            # Type II & Type III\n",
    "            if end1 is not None: \n",
    "\n",
    "                orig_serv = nr_pci\n",
    "                nr_pci = 'O'\n",
    "                _, idx = find_1st_before_with_special_value(i, 'PCI', rlf_cell, look_before=10)\n",
    "                rlf_freq = int(df['Freq'].iloc[idx])\n",
    "                trans = f'({rlf_cell}, {rlf_freq}) -> ({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                D['RLF_II'].append(HO(start=t,end=end1,others=others,trans=trans))\n",
    "\n",
    "                lte_pci = serv_cell\n",
    "                lte_earfcn = serv_freq\n",
    "\n",
    "            elif b is not None and end2 is not None:\n",
    "                \n",
    "                orig_serv = nr_pci\n",
    "                nr_pci = 'O'\n",
    "                _, idx = find_1st_before_with_special_value(i, 'PCI', rlf_cell, look_before=10)\n",
    "                rlf_freq = int(df['Freq'].iloc[idx])\n",
    "\n",
    "                _, idx = find_1st_after(i, \"rrcConnectionRequest\", 2)\n",
    "                recon_cell, recon_freq = df['PCI'].iloc[idx], int(float(df['Freq'].iloc[idx]))\n",
    "                \n",
    "                trans = f'({rlf_cell}, {rlf_freq}) -> ({recon_cell}, {recon_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                D['RLF_III'].append(HO(start=t,end=end2,others=others,trans=trans)) \n",
    "\n",
    "                # lte_pci, lte_earfcn will be updated in rrcConnectionRequest.     \n",
    "                \n",
    "            else:\n",
    "\n",
    "                others+=' No end.'\n",
    "                D['RLF_II'].append(HO(start=t,others=others))\n",
    "                print('No end for RLF')\n",
    "\n",
    "        if df[\"scgFailureInformationNR-r15\"].iloc[i] == 1:\n",
    "\n",
    "            others += ' ' + df[\"failureType-r15\"].iloc[i] + '.'\n",
    "            a, idx1 = find_1st_after(i, \"rrcConnectionReestablishmentRequest\", look_after=1)\n",
    "            b, idx2 = find_1st_after(i, \"lte-rrc.t304\", look_after=10)\n",
    "\n",
    "            if a is not None:\n",
    "\n",
    "                end1, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "                b, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "                end2 = find_1st_after(idx1, 'securityModeComplete',look_after=3)[0]\n",
    "\n",
    "                others += ' Result in rrcReestablishment.'\n",
    "                    \n",
    "                # Type II & Type III Result\n",
    "                if end1 is not None: \n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end1,others=others))\n",
    "                elif b is not None and end2 is not None: \n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end2,others=others))\n",
    "                else:\n",
    "                    others += ' No end.'\n",
    "                    D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "                    print('No end for scg failure result in rrcReestablishment.')\n",
    "\n",
    "            elif b is not None:\n",
    "\n",
    "                end, _ = find_1st_after(idx2, 'rrcConnectionReconfigurationComplete')\n",
    "                serv_cell, target_cell = df[\"PCI\"].iloc[idx2], df['lte_targetPhysCellId'].iloc[idx2]\n",
    "                serv_freq, target_freq = int(df[\"Freq\"].iloc[idx2]), df['dl-CarrierFreq'].iloc[idx2]\n",
    "                # We do not change nr_pci here. Instead, we will change it at gNB_Rel event.\n",
    "                trans = f'({serv_cell}, {serv_freq}) | {nr_pci} -> O'\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "                    others += ' Result in gNB release.'\n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end,others=others,trans=trans))\n",
    "                else:\n",
    "                    others += ' Result in MN HO to eNB.'\n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end,others=others,trans=trans))                  \n",
    "\n",
    "            else:\n",
    "\n",
    "                print('No end for scg failure.')\n",
    "                others += ' No end.'\n",
    "                D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "        \n",
    "        if df['SCellToAddMod-r10'].iloc[i] == 1 and df['physCellId-r10'].iloc[i] != 'nr or cqi report':\n",
    "\n",
    "            others = ''\n",
    "            pcis = str(df[\"physCellId-r10\"].iloc[i]).split('@')\n",
    "            freqs = str(df[\"dl-CarrierFreq-r10\"].iloc[i]).split('@')\n",
    "            orig_scells = scells\n",
    "            scells = [(int(float(pci)), int(float(freq))) for pci, freq in zip(pcis, freqs)]\n",
    "\n",
    "            others += f' Set up {len(scells)} SCell.'\n",
    "            trans = f'{orig_scells} -> {scells}'\n",
    "\n",
    "            end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "            \n",
    "            a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 3)\n",
    "            if a is not None:\n",
    "                others += ' Near after RLF.'\n",
    "\n",
    "            a = find_in_D_exact(['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel'])\n",
    "            if a is not None:\n",
    "                others += f' With {a}.'\n",
    "\n",
    "            D['Add_SCell'].append(HO(start=t,end=end,others=others, trans=trans))\n",
    "    \n",
    "    return D\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REPORTCONFIG:\n",
    "    def __init__(self, name, parameter):\n",
    "        self.name = name.split(' ')[0]  \n",
    "        self.parameters = self.parse_parameter(parameter)\n",
    "    \n",
    "    def parse_parameter(self, parameter):\n",
    "        L = []\n",
    "        start = False\n",
    "        for i in range(len(parameter)):\n",
    "            if parameter[i] == \"'\" and start == False:\n",
    "                s = ''\n",
    "                start = True\n",
    "                continue\n",
    "            \n",
    "            if start:\n",
    "                if parameter[i] == \"'\":\n",
    "                    L.append(s)\n",
    "                    start = False\n",
    "                s += parameter[i]\n",
    "        \n",
    "        P = dict()\n",
    "        filter = '+-0123456789[]()&'\n",
    "        for i in range(0,len(L),2):\n",
    "            x = ''\n",
    "            for c in L[i+1]:\n",
    "                if c in filter:\n",
    "                    x += c\n",
    "            try:\n",
    "                P[L[i]] = int(x)\n",
    "            except:\n",
    "                P[L[i]] = x\n",
    "        return P\n",
    "    \n",
    "    def reset_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "\n",
    "class MEASOBJ:\n",
    "\n",
    "    def __init__(self, obj, freq):\n",
    "        self.name = obj\n",
    "        self.freq = freq\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'({self.name}, {self.freq})'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'({self.name}, {self.freq})'\n",
    "\n",
    "def parse_measIdToAddMod(s):\n",
    "    a = s.replace('(','')\n",
    "    a = a.replace(')','')\n",
    "    a = a.split('&')\n",
    "    return (a[0], a[1], a[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeasureReport(file):\n",
    "\n",
    "    mi_rrc_df = pd.read_csv(file)\n",
    "    mi_rrc_df[\"Timestamp\"] = mi_rrc_df[\"Timestamp\"].swifter.apply(lambda x: pd.to_datetime(x) + dt.timedelta(hours=8))\n",
    "    unused = ['DL frequency','UL frequency', 'DL bandwidth', 'UL bandwidth', 'Cell Identity', 'TAC','Band ID', 'MCC', 'MNC']\n",
    "    mi_rrc_df = mi_rrc_df.drop(columns=unused)\n",
    "    mi_rrc_df = mi_rrc_df.dropna()    \n",
    "    cols_to_covert = ['measObjectId', 'carrierFreq', 'carrierFreq-r15', 'lte-reportConfigId', 'lte-measIdToRemoveList', 'measId', 'ssbFrequency']\n",
    "    mi_rrc_df[cols_to_covert] = mi_rrc_df[cols_to_covert].astype('str')\n",
    "\n",
    "    measobj_dict, report_config_dict, measId_dict = {}, {}, {}\n",
    "    nr_measobj_dict, nr_report_config_dict, nr_measId_dict = {}, {}, {}\n",
    "\n",
    "    def reset():\n",
    "\n",
    "        global measobj_dict, report_config_dict, measId_dict, nr_measobj_dict, nr_report_config_dict, nr_measId_dict  \n",
    "        measobj_dict, report_config_dict, measId_dict = {}, {}, {}\n",
    "        nr_measobj_dict, nr_report_config_dict, nr_measId_dict = {}, {}, {}\n",
    "\n",
    "    MR = namedtuple('MR',['time', 'event', 'others'], defaults=[None,None,''])\n",
    "    L = []\n",
    "\n",
    "    RRC_connected = True\n",
    "    Unknown = REPORTCONFIG('Unknown', {})\n",
    "\n",
    "    for i in range(len(mi_rrc_df)):\n",
    "\n",
    "        if mi_rrc_df['type_id'].iloc[i] == \"5G_NR_RRC_OTA_Packet\" or mi_rrc_df['type_id'].iloc[i] == \"LTE_RRC_Serv_Cell_Info\":\n",
    "            continue\n",
    "\n",
    "        time = mi_rrc_df['Timestamp'].iloc[i]\n",
    "        others = ''\n",
    "        \n",
    "        # if mi_rrc_df[\"rrcConnectionRelease\"].iloc[i] == 1:      \n",
    "        #     reset()\n",
    "\n",
    "        if mi_rrc_df[\"lte-measIdToRemoveList\"].iloc[i] != '0':\n",
    "\n",
    "            measIdToRemove_list = mi_rrc_df[\"lte-measIdToRemoveList\"].iloc[i].split('@')\n",
    "            if len(measIdToRemove_list) == 32:\n",
    "                measId_dict = {}\n",
    "            elif len(measId_dict) != 0:\n",
    "                for a in range(len(measIdToRemove_list)):\n",
    "                    try: measId_dict.pop(measIdToRemove_list[a])\n",
    "                    except: pass\n",
    "\n",
    "        if mi_rrc_df[\"lte-measurementReport\"].iloc[i] == 1:\n",
    "            \n",
    "            others += 'E-UTRAN'\n",
    "            id = str(int(float(mi_rrc_df['measId'].iloc[i])))\n",
    "\n",
    "            try:\n",
    "                x = measId_dict[id]\n",
    "                event = report_config_dict[x[1]]\n",
    "                mr = MR(time = time, event = event, others = others)\n",
    "            except:\n",
    "                mr = MR(time = time, event = copy.deepcopy(Unknown), others = others)\n",
    "\n",
    "            L.append(mr)\n",
    "\n",
    "        if mi_rrc_df[\"nr-measurementReport\"].iloc[i] == 1:\n",
    "            \n",
    "            others += 'NR'\n",
    "            id = str(int(float(mi_rrc_df['measId'].iloc[i])))\n",
    "\n",
    "            try:\n",
    "                x = nr_measId_dict[id]\n",
    "                event = nr_report_config_dict[x[1]]\n",
    "                mr = MR(time = time, event = event, others = others)\n",
    "            except:\n",
    "                mr = MR(time = time, event = copy.deepcopy(Unknown), others = others)\n",
    "            \n",
    "            L.append(mr)\n",
    "\n",
    "        if mi_rrc_df[\"lte-MeasObjectToAddMod\"].iloc[i] == 1:\n",
    "\n",
    "            Id_list = mi_rrc_df[\"measObjectId\"].iloc[i].split('@')\n",
    "            measobj_list = mi_rrc_df[\"measObject\"].iloc[i].split('@')\n",
    "            carrierFreq_list = mi_rrc_df[\"carrierFreq\"].iloc[i].split('@')\n",
    "            carrierFreq_r15_list = mi_rrc_df[\"carrierFreq-r15\"].iloc[i].split('@')\n",
    "            \n",
    "            for a in range(len(Id_list)):\n",
    "                if measobj_list[a] == \"measObjectEUTRA (0)\":\n",
    "                    measobj_dict[Id_list[a]] = MEASOBJ(measobj_list[a], carrierFreq_list[0])\n",
    "                    carrierFreq_list.pop(0)\n",
    "                elif measobj_list[a] == \"measObjectNR-r15 (5)\":\n",
    "                    measobj_dict[Id_list[a]] = MEASOBJ(measobj_list[a], carrierFreq_r15_list[0])\n",
    "                    carrierFreq_r15_list.pop(0)\n",
    "    \n",
    "\n",
    "        if mi_rrc_df[\"nr-MeasObjectToAddMod\"].iloc[i] == 1:\n",
    "\n",
    "            Id_list = mi_rrc_df[\"measObjectId\"].iloc[i].split('@')\n",
    "            measobj_list = mi_rrc_df[\"measObject\"].iloc[i].split('@')\n",
    "            ssbFrequency_list = mi_rrc_df[\"ssbFrequency\"].iloc[i].split('@')\n",
    "\n",
    "            for a in range(len(Id_list)):\n",
    "                if measobj_list[a] == \"measObjectNR (0)\":\n",
    "                    nr_measobj_dict[Id_list[a]] = MEASOBJ(measobj_list[a], ssbFrequency_list[0])\n",
    "                    ssbFrequency_list.pop(0)     \n",
    "\n",
    "            \n",
    "        if mi_rrc_df[\"lte-ReportConfigToAddMod\"].iloc[i] == 1:\n",
    "\n",
    "            reportConfigId_list = mi_rrc_df[\"lte-reportConfigId\"].iloc[i].split('@')\n",
    "            eventId_list = mi_rrc_df[\"lte-eventId\"].iloc[i].split('@')\n",
    "            parameter_list = mi_rrc_df[\"lte-parameter\"].iloc[i].split('@')\n",
    "            for a in range(len(reportConfigId_list)):\n",
    "                report_config_dict[reportConfigId_list[a]] = REPORTCONFIG(eventId_list[a], parameter_list[a])\n",
    "\n",
    "\n",
    "        if mi_rrc_df[\"nr-ReportConfigToAddMod\"].iloc[i] == 1: #############\n",
    "\n",
    "            reportConfigId_list = mi_rrc_df[\"nr-reportConfigId\"].iloc[i].split('@')\n",
    "            eventId_list = mi_rrc_df[\"nr-eventId\"].iloc[i].split('@')\n",
    "            parameter_list = mi_rrc_df[\"nr-parameter\"].iloc[i].split('@')\n",
    "            for a in range(len(reportConfigId_list)):\n",
    "                nr_report_config_dict[reportConfigId_list[a]] = REPORTCONFIG(eventId_list[a], parameter_list[a])\n",
    "\n",
    "        if mi_rrc_df[\"lte-MeasIdToAddMod\"].iloc[i] != '0':\n",
    "\n",
    "            MeasIdToAdd_list = mi_rrc_df[\"lte-MeasIdToAddMod\"].iloc[i].split('@')\n",
    "            for a in range(len(MeasIdToAdd_list)):\n",
    "                x = parse_measIdToAddMod(MeasIdToAdd_list[a])\n",
    "                measId_dict[x[0]] = (x[1],x[2])\n",
    "\n",
    "\n",
    "        if mi_rrc_df[\"nr-MeasIdToAddMod\"].iloc[i] != '0' and mi_rrc_df[\"nr-MeasIdToAddMod\"].iloc[i] != 0:\n",
    "\n",
    "            MeasIdToAdd_list = mi_rrc_df[\"nr-MeasIdToAddMod\"].iloc[i].split('@')\n",
    "            for a in range(len(MeasIdToAdd_list)):\n",
    "                x = parse_measIdToAddMod(MeasIdToAdd_list[a])\n",
    "                nr_measId_dict[x[0]] = (x[1],x[2])\n",
    "\n",
    "    # Sort to Dict\n",
    "    types = ['eventA1','eventA2','E-UTRAN-eventA3', 'eventA5', 'eventA6','NR-eventA3', 'eventB1-NR-r15','reportCGI', 'reportStrongestCells', 'others']\n",
    "    D = {k: [] for k in types}\n",
    "\n",
    "    for mr in L:\n",
    "\n",
    "        if 'E-UTRAN' in mr.others and 'eventA1' in mr.event.name:\n",
    "            D['eventA1'].append(mr)\n",
    "        \n",
    "        elif 'E-UTRAN' in mr.others and 'eventA2' in mr.event.name:\n",
    "            D['eventA2'].append(mr)  \n",
    "        \n",
    "        elif 'E-UTRAN' in mr.others and 'eventA3' in mr.event.name:\n",
    "            D['E-UTRAN-eventA3'].append(mr)\n",
    "        \n",
    "        elif 'E-UTRAN' in mr.others and 'eventA5' in mr.event.name:\n",
    "            D['eventA5'].append(mr)\n",
    "\n",
    "        elif 'E-UTRAN' in mr.others and 'eventA6' in mr.event.name:\n",
    "            D['eventA6'].append(mr)  \n",
    "        \n",
    "        elif 'E-UTRAN' in mr.others and 'eventB1-NR-r15' in mr.event.name:\n",
    "            D['eventB1-NR-r15'].append(mr)\n",
    "        \n",
    "        elif 'E-UTRAN' in mr.others and 'reportCGI' in mr.event.name:\n",
    "            D['reportCGI'].append(mr)\n",
    "        \n",
    "        elif 'E-UTRAN' in mr.others and 'reportStrongestCells' in mr.event.name:\n",
    "            D['reportStrongestCells'].append(mr)\n",
    "        \n",
    "        elif 'NR' in mr.others and 'eventA3' in mr.event.name:\n",
    "            D['NR-eventA3'].append(mr)       \n",
    "        \n",
    "        else:\n",
    "            D['others'].append(mr)\n",
    "\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map MeasureReport with HO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_MR_HO(MRs, HOs):\n",
    "\n",
    "    map_ho_types = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel', 'SN_HO', ]\n",
    "    map_mr_types = ['E-UTRAN-eventA3', 'eventA5', 'eventB1-NR-r15', 'NR-eventA3']\n",
    "\n",
    "    D = {'LTE_HO': [], 'NR_HO': [], 'SN_setup': []}\n",
    "\n",
    "    for lte_ho_type in ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB']:\n",
    "        for ho in HOs[lte_ho_type]:\n",
    "            for mr_type in ['E-UTRAN-eventA3', 'eventA5']:\n",
    "                \n",
    "                for mr in MRs[mr_type]:\n",
    "                    # The current mapping way may map a HO with repeated measurement report.\n",
    "                    dif = (ho.start - mr.time).total_seconds()\n",
    "                    if 0 < dif < 0.5:\n",
    "                        D['LTE_HO'].append((mr, ho, lte_ho_type))\n",
    "\n",
    "    for nr_ho_type in ['SN_Rel', 'SN_HO']:\n",
    "        for ho in HOs[nr_ho_type]:\n",
    "            for mr in MRs['NR-eventA3']:\n",
    "\n",
    "                dif = (ho.start - mr.time).total_seconds()\n",
    "                if 0 < dif < 0.5:\n",
    "                    D['NR_HO'].append((mr, ho, nr_ho_type))\n",
    "\n",
    "    for ho in HOs['SN_setup']:\n",
    "        for mr in MRs['eventB1-NR-r15']:\n",
    "\n",
    "            dif = (ho.start - mr.time).total_seconds()\n",
    "            if 0 < dif < 0.5:\n",
    "                D['SN_setup'].append((mr, ho, 'SN_setup'))\n",
    "\n",
    "    return D \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct MR with HO\n",
    "def correct_MR_with_HO(MRs, HOs):\n",
    "    MR = namedtuple('MR',['time', 'event', 'others'], defaults=[None,None,''])\n",
    "    new_MRs = copy.deepcopy(MRs)\n",
    "    del new_MRs['others']\n",
    "\n",
    "    for mr in MRs['others']:\n",
    "        if 'E-UTRAN' in mr.others:\n",
    "            for ho in HOs['LTE_HO'] + HOs['MN_HO']:\n",
    "                if 0.3 > (ho.start - mr.time).total_seconds() > 0:\n",
    "                    mr.event.reset_name('eventA3')\n",
    "                    new_MRs['E-UTRAN-eventA3'].append(MR(time = mr.time, event = mr.event, others = mr.others))\n",
    "    \n",
    "        elif 'NR' in mr.others:\n",
    "            for ho in HOs['SN_HO']:\n",
    "                if 0.3 > (ho.start - mr.time).total_seconds() > 0:\n",
    "                    mr.event.reset_name('eventA3')\n",
    "                    new_MRs['NR-eventA3'].append(MR(time = mr.time, event = mr.event, others = mr.others))\n",
    "    \n",
    "    return new_MRs                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UE State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UE_state(file):\n",
    "\n",
    "    mi_rrc_df = pd.read_csv(file)\n",
    "    mi_rrc_df[\"Timestamp\"] = mi_rrc_df[\"Timestamp\"].swifter.apply(lambda x: pd.to_datetime(x) + dt.timedelta(hours=8))\n",
    "    unused = ['DL frequency','UL frequency', 'DL bandwidth', 'UL bandwidth', 'Cell Identity', 'TAC','Band ID', 'MCC', 'MNC']\n",
    "    mi_rrc_df = mi_rrc_df.drop(columns=unused)\n",
    "    mi_rrc_df = mi_rrc_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HO Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colored output text\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "def print_trans(HOs, p=True, mappings=None):\n",
    "\n",
    "    All_HOs = []\n",
    "    selected = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel', 'SN_HO', \n",
    "    'Conn_Req' ,'RLF_II', 'RLF_III', 'SCG_RLF']\n",
    "\n",
    "    def find_mr(target, ho):\n",
    "        for mapping in target:\n",
    "            map_ho = mapping[1]\n",
    "            if ho == map_ho:\n",
    "                mr = mapping[0]\n",
    "                return mr\n",
    "        return None\n",
    "\n",
    "    for type in selected:\n",
    "\n",
    "        for ho in HOs[type]:\n",
    "\n",
    "            if type in ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB'] and mappings is not None:\n",
    "            \n",
    "                target = mappings['LTE_HO']\n",
    "                mr = find_mr(target, ho)\n",
    "                \n",
    "                if mr is not None and 0 < (ho.start - mr.time).total_seconds() < 0.5: \n",
    "                    All_HOs.append([type, ho, mr])\n",
    "                else:\n",
    "                    All_HOs.append([type, ho])\n",
    "\n",
    "            elif type in ['SN_Rel', 'SN_HO'] and mappings is not None:\n",
    "            \n",
    "                target = mappings['NR_HO']\n",
    "                mr = find_mr(target, ho)\n",
    "\n",
    "                if mr is not None and 0 < (ho.start - mr.time).total_seconds() < 0.5: \n",
    "                    All_HOs.append([type, ho, mr])\n",
    "                else:\n",
    "                    All_HOs.append([type, ho])\n",
    "\n",
    "            elif type in ['SN_setup'] and mappings is not None:\n",
    "            \n",
    "                target = mappings['SN_setup']\n",
    "                mr = find_mr(target, ho)\n",
    "\n",
    "                if mr is not None and 0 < (ho.start - mr.time).total_seconds() < 0.5: \n",
    "                    All_HOs.append([type, ho, mr])\n",
    "                else:\n",
    "                    All_HOs.append([type, ho])\n",
    "                \n",
    "            else:\n",
    "                All_HOs.append([type, ho])\n",
    "\n",
    "    All_HOs = sorted(All_HOs, key = lambda x: x[1].start)\n",
    "\n",
    "    if p:\n",
    "        for ho in All_HOs:\n",
    "            if len(ho) == 3:\n",
    "                print(f'{ho[1].start} | {bcolors.OKBLUE}{ho[0]}{bcolors.ENDC} | {bcolors.OKCYAN}{ho[1].trans}{bcolors.ENDC} | {bcolors.OKGREEN}{ho[2].event.name}{bcolors.ENDC} | {ho[2].event.parameters}')\n",
    "            elif len(ho) == 2:\n",
    "                print(f'{ho[1].start} | {bcolors.OKBLUE}{ho[0]}{bcolors.ENDC} | {bcolors.OKCYAN}{ho[1].trans}{bcolors.ENDC}')\n",
    "\n",
    "    return All_HOs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss/Excl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_excl_cause(loss_lat_file_path, rrc_file_path):\n",
    "\n",
    "    loss_lat_df = pd.read_csv(loss_lat_file_path)\n",
    "\n",
    "    loss_cond = loss_lat_df['lost'] == True\n",
    "    loss_packets = loss_lat_df[loss_cond]\n",
    "    loss_packets = loss_packets.reset_index(drop=True)\n",
    "    loss_packets['Timestamp'] = pd.to_datetime(loss_packets['Timestamp'])\n",
    "\n",
    "    exc_lat = 0.1\n",
    "    excl_cond = (loss_cond==False) & (loss_lat_df['latency'] > exc_lat)\n",
    "    excl_packets = loss_lat_df[excl_cond]\n",
    "    excl_packets = excl_packets.reset_index(drop=True)\n",
    "    excl_packets['Timestamp'] = pd.to_datetime(excl_packets['Timestamp'])\n",
    "\n",
    "    HO_dict = parse_mi_ho(rrc_file_path)\n",
    "    events = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', \n",
    "              'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF',\n",
    "              'Conn_Req']\n",
    "    slots = [dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1),\n",
    "             dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=2), dt.timedelta(seconds=2), dt.timedelta(seconds=2),\n",
    "             dt.timedelta(seconds=1)]\n",
    "    \n",
    "    LOSS_PKT = namedtuple('LOSS_PKT',['timestamp', 'seq', 'cause', 'trans', 'trans_time', 'others'], defaults=['', 0, [], [], [], []])\n",
    "\n",
    "    LOSS_PKTs = []\n",
    "\n",
    "    for i in range(len(loss_packets)):\n",
    "\n",
    "        loss_packet = loss_packets.iloc[i]\n",
    "        loss_packet_timestamp = loss_packet['Timestamp']\n",
    "        seq = loss_packet['seq']\n",
    "        \n",
    "        cause = []\n",
    "        trans = []\n",
    "        others = []\n",
    "        trans_time = []\n",
    "\n",
    "        for HO_type, slot in zip(events, slots):\n",
    "            \n",
    "            HOs = HO_dict[HO_type]  \n",
    "\n",
    "            for h in HOs:\n",
    "                \n",
    "                if h.start - slot < loss_packet_timestamp < h.start:\n",
    "                    cause.append(f'Before {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append(h.start)\n",
    "                    others.append(h.others)\n",
    "                elif (h.end is not None) and (h.start < loss_packet_timestamp < h.end):\n",
    "                    cause.append(f'During {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append((h.start, h.end))\n",
    "                    others.append(h.others)\n",
    "                elif (h.end is not None) and (h.end < loss_packet_timestamp < h.end + slot):\n",
    "                    cause.append(f'After {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append(h.end)\n",
    "                    others.append(h.others)\n",
    "\n",
    "        LOSS_PKTs.append(LOSS_PKT(timestamp=loss_packet_timestamp, seq=seq, cause=cause, others=others))\n",
    "                \n",
    "    EXCL_PKT = namedtuple('EXCL_PKT',['timestamp', 'seq', 'cause', 'trans', 'trans_time', 'others'], defaults=['', 0, [], [], [], []])\n",
    "\n",
    "    events = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', \n",
    "              'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF',\n",
    "              'Conn_Req']\n",
    "    slots = [dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1),\n",
    "             dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=2), dt.timedelta(seconds=2), dt.timedelta(seconds=1),\n",
    "             dt.timedelta(seconds=1)]\n",
    "    \n",
    "    EXCL_PKTs = []\n",
    "\n",
    "    for i in range(len(excl_packets)):\n",
    "\n",
    "        excl_packet = excl_packets.iloc[i]\n",
    "        excl_packet_timestamp = excl_packet['Timestamp']\n",
    "        seq = excl_packet['seq']\n",
    "\n",
    "        cause = []\n",
    "        trans = []\n",
    "        trans_time = []\n",
    "        others = []\n",
    "\n",
    "        for HO_type, slot in zip(events, slots):\n",
    "            \n",
    "            HOs = HO_dict[HO_type]   \n",
    "            for h in HOs:\n",
    "                \n",
    "                if h.start - slot < excl_packet_timestamp < h.start:\n",
    "                    cause.append(f'Before {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append(h.start)\n",
    "                    others.append(h.others)\n",
    "                elif (h.end is not None) and (h.start < excl_packet_timestamp < h.end):\n",
    "                    cause.append(f'During {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append((h.start, h.end))\n",
    "                    others.append(h.others)\n",
    "                elif (h.end is not None) and (h.end < excl_packet_timestamp < h.end + slot):\n",
    "                    cause.append(f'After {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append(h.end)\n",
    "                    others.append(h.others)\n",
    "\n",
    "        EXCL_PKTs.append(EXCL_PKT(timestamp=excl_packet_timestamp, seq=seq, cause=cause, trans=trans, trans_time=trans_time, others=others))\n",
    "    \n",
    "    return LOSS_PKTs, EXCL_PKTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_excl_cause_dual(loss_lat_file_path1, loss_lat_file_path2, rrc_file_path1, rrc_file_path2):\n",
    "\n",
    "    df1 = pd.read_csv(loss_lat_file_path1)\n",
    "    df2 = pd.read_csv(loss_lat_file_path2)\n",
    "\n",
    "    start_seq = df1['seq'].iloc[0] if df1['seq'].iloc[0] >=  df2['seq'].iloc[0] else df2['seq'].iloc[0]\n",
    "    end_seq = df1['seq'].iloc[-1] if df1['seq'].iloc[-1] <=  df2['seq'].iloc[-1] else df2['seq'].iloc[-1]\n",
    "\n",
    "    cond1 = (df1['seq'] >= start_seq) & (df1['seq'] <= end_seq)\n",
    "    df1 = df1[cond1]\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    cond2 = (df2['seq'] >= start_seq) & (df2['seq'] <= end_seq)\n",
    "    df2 = df2[cond2]\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "\n",
    "    # Loss calculate for dual radios redundant packets.\n",
    "    loss_cond = (df1['lost'] == True) & (df2['lost'] == True)\n",
    "\n",
    "    loss_packets1 = df1[loss_cond]\n",
    "    loss_packets1 = loss_packets1.reset_index(drop=True)\n",
    "    loss_packets1['Timestamp'] = pd.to_datetime(loss_packets1['Timestamp'])\n",
    "\n",
    "    loss_packets2 = df2[loss_cond]\n",
    "    loss_packets2 = loss_packets2.reset_index(drop=True)\n",
    "    loss_packets2['Timestamp'] = pd.to_datetime(loss_packets2['Timestamp'])\n",
    "\n",
    "    # Excexxive latency calculate for dual radios redundant packets.\n",
    "    exc_lat = 0.1 \n",
    "    excl_cond1 = (loss_cond==False) & (df1['latency'] > exc_lat)\n",
    "    excl_cond2 = (loss_cond==False) & (df2['latency'] > exc_lat)\n",
    "    excl_cond = (excl_cond1 == True) & (excl_cond2 == True)\n",
    "    \n",
    "    excl_packets1 = df1[excl_cond]\n",
    "    excl_packets1 = excl_packets1.reset_index(drop=True)\n",
    "    excl_packets1['Timestamp'] = pd.to_datetime(excl_packets1['Timestamp'])\n",
    "\n",
    "    excl_packets2 = df2[excl_cond]\n",
    "    excl_packets2 = excl_packets2.reset_index(drop=True)\n",
    "    excl_packets2['Timestamp'] = pd.to_datetime(excl_packets2['Timestamp'])\n",
    "\n",
    "    HO_dict1 = parse_mi_ho(rrc_file_path1)\n",
    "    HO_dict2 = parse_mi_ho(rrc_file_path2)\n",
    "    \n",
    "    events = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', \n",
    "              'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF',\n",
    "              'Conn_Req']\n",
    "    slots = [dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1),\n",
    "             dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=2), dt.timedelta(seconds=2), dt.timedelta(seconds=2),\n",
    "             dt.timedelta(seconds=1)]\n",
    "    \n",
    "    LOSS_PKT_DUAL = namedtuple('LOSS_PKT_DUAL',\n",
    "                               ['timestamp1', 'timestamp2', 'seq', 'cause1', 'cause2', 'trans1', 'trans2', 'others1', 'others2','trans1_time', 'trans2_time'], \n",
    "                               defaults=['', '', 0, [], [], [], [], [], [], [], []])\n",
    "\n",
    "    LOSS_PKT_DUALs = []\n",
    "\n",
    "    for i in range(len(loss_packets1)):\n",
    "\n",
    "        loss_packet1 = loss_packets1.iloc[i]\n",
    "        loss_packet1_timestamp = loss_packet1['Timestamp']\n",
    "\n",
    "        loss_packet2 = loss_packets2.iloc[i]\n",
    "        loss_packet2_timestamp = loss_packet2['Timestamp']\n",
    "\n",
    "        seq = loss_packet1['seq']\n",
    "        \n",
    "        cause1, cause2 = [], []\n",
    "        trans1, trans2 = [], []\n",
    "        others1, others2 = [], []\n",
    "        trans1_time, trans2_time = [], []\n",
    "\n",
    "        for HO_type, slot in zip(events, slots):\n",
    "            \n",
    "            HOs1 = HO_dict1[HO_type]\n",
    "            HOs2 = HO_dict2[HO_type]   \n",
    "\n",
    "            for h in HOs1:\n",
    "                \n",
    "                if h.start - slot < loss_packet1_timestamp < h.start:\n",
    "                    cause1.append(f'Before {HO_type}') \n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append(h.start)\n",
    "                    others1.append(h.others)\n",
    "\n",
    "                elif (h.end is not None) and (h.start < loss_packet1_timestamp < h.end):\n",
    "                    cause1.append(f'During {HO_type}')\n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append((h.start, h.end))\n",
    "                    others1.append(h.others)\n",
    "\n",
    "                elif (h.end is not None) and (h.end < loss_packet1_timestamp < h.end + slot):\n",
    "                    cause1.append(f'After {HO_type}')\n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append(h.end)\n",
    "                    others1.append(h.others)\n",
    "            \n",
    "            for h in HOs2:\n",
    "                \n",
    "                if h.start - slot < loss_packet2_timestamp < h.start:\n",
    "                    cause2.append(f'Before {HO_type}') \n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append(h.start)\n",
    "                    others2.append(h.others)\n",
    "\n",
    "                elif (h.end is not None) and (h.start < loss_packet2_timestamp < h.end):\n",
    "                    cause2.append(f'During {HO_type}')\n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append((h.start, h.end))\n",
    "                    others2.append(h.others)\n",
    "\n",
    "                elif (h.end is not None) and (h.end < loss_packet2_timestamp < h.end + slot):\n",
    "                    cause2.append(f'After {HO_type}')\n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append(h.end)\n",
    "                    others2.append(h.others)\n",
    "    \n",
    "        LOSS_PKT_DUALs.append(LOSS_PKT_DUAL(timestamp1=loss_packet1_timestamp, timestamp2=loss_packet2_timestamp, seq=seq, \n",
    "        cause1=cause1, cause2=cause2, trans1=trans1, trans2=trans2, others1=others1, others2=others2, trans1_time=trans1_time, trans2_time=trans2_time))\n",
    "                \n",
    "    slot = dt.timedelta(seconds=2)\n",
    "    EXCL_PKT_DUAL = namedtuple('EXCL_PKT_DUAL',\n",
    "                               ['timestamp1', 'timestamp2', 'seq', 'cause1', 'cause2', 'trans1', 'trans2', 'others1', 'others2','trans1_time', 'trans2_time'], \n",
    "                               defaults=['', '', 0, [], [], [], [], [], [], [], []])\n",
    "\n",
    "    events = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', \n",
    "              'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF',\n",
    "              'Conn_Req']\n",
    "    slots = [dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1),\n",
    "             dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=2), dt.timedelta(seconds=2), dt.timedelta(seconds=2),\n",
    "             dt.timedelta(seconds=1)]\n",
    "    \n",
    "    \n",
    "    EXCL_PKT_DUALs = []\n",
    "\n",
    "    for i in range(len(excl_packets1)):\n",
    "\n",
    "        excl_packet1 = excl_packets1.iloc[i]\n",
    "        excl_packet1_timestamp = excl_packet1['Timestamp']\n",
    "        excl_packet2 = excl_packets2.iloc[i]\n",
    "        excl_packet2_timestamp = excl_packet2['Timestamp']\n",
    "\n",
    "        seq = excl_packet1['seq']\n",
    "\n",
    "        cause1, cause2 = [], []\n",
    "        trans1, trans2 = [], []\n",
    "        others1, others2 = [], []\n",
    "        trans1_time, trans2_time = [], []\n",
    "\n",
    "        for HO_type, slot in zip(events, slots):\n",
    "            \n",
    "            HOs1 = HO_dict1[HO_type]\n",
    "            HOs2 = HO_dict2[HO_type]\n",
    "\n",
    "            for h in HOs1:\n",
    "                \n",
    "                if h.start - slot < excl_packet1_timestamp < h.start:\n",
    "                    cause1.append(f'Before {HO_type}') \n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append(h.start)\n",
    "                    others1.append(h.others)\n",
    "\n",
    "                elif (h.end is not None) and (h.start < excl_packet1_timestamp < h.end):\n",
    "                    cause1.append(f'During {HO_type}')\n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append((h.start, h.end))\n",
    "                    others1.append(h.others)\n",
    "\n",
    "                elif (h.end is not None) and (h.end < excl_packet1_timestamp < h.end + slot):\n",
    "                    cause1.append(f'After {HO_type}')\n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append(h.end)\n",
    "                    others1.append(h.others)\n",
    "\n",
    "            for h in HOs2:\n",
    "                \n",
    "                if h.start - slot < excl_packet2_timestamp < h.start:\n",
    "                    cause2.append(f'Before {HO_type}') \n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append(h.start)\n",
    "                    others2.append(h.others)\n",
    "\n",
    "                elif (h.end is not None) and (h.start < excl_packet2_timestamp < h.end):\n",
    "                    cause2.append(f'During {HO_type}')\n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append((h.start, h.end))\n",
    "                    others2.append(h.others)\n",
    "\n",
    "                elif (h.end is not None) and (h.end < excl_packet2_timestamp < h.end + slot):\n",
    "                    cause2.append(f'After {HO_type}')\n",
    "                    trans2.append(h.trans)                   \n",
    "                    trans2_time.append(h.end)\n",
    "                    others2.append(h.others)\n",
    "\n",
    "        EXCL_PKT_DUALs.append(EXCL_PKT_DUAL(timestamp1=excl_packet1_timestamp, timestamp2=excl_packet2_timestamp, seq=seq, \n",
    "        cause1=cause1, cause2=cause2, trans1=trans1, trans2=trans2, others1=others1, others2=others2, trans1_time=trans1_time, trans2_time=trans2_time))\n",
    "\n",
    "    return LOSS_PKT_DUALs, EXCL_PKT_DUALs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PKG = namedtuple('PKG',['Timestamp','seq','latency'],defaults=[None,0,np.nan])\n",
    "\n",
    "def accumulate_packet(file,time_range):\n",
    "\n",
    "    L = []\n",
    "    df = pd.read_csv(file)\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "    hys = dt.timedelta(seconds=0.2)\n",
    "    start_time = time_range[0] - hys\n",
    "    end_time = time_range[1] + hys\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        t = df['Timestamp'].iloc[i]\n",
    "        if t < start_time: continue\n",
    "        elif start_time <= t < end_time: pass\n",
    "        elif end_time <= t: break\n",
    "\n",
    "        if df['lost'].iloc[i]: continue\n",
    "        \n",
    "        seq = df['seq'].iloc[i]\n",
    "        lat = df['latency'].iloc[i]\n",
    "        \n",
    "        L.append(PKG(t,seq,lat))\n",
    "\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTE RSRP/RSRQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = namedtuple('SS', ['PCI', 'earfcn', 'RSRP', 'RSRQ', 'Timestamp'], defaults=['','',0,0,None])\n",
    "\n",
    "def LTE_signal_strength(ml1_file, time_range, cut=True):\n",
    "    # Read csv with pandas\n",
    "    ml1_df = pd.read_csv(ml1_file)\n",
    "    ml1_df['Timestamp'] = pd.to_datetime(ml1_df['Timestamp'])\n",
    "    ml1_df['Timestamp'] = ml1_df['Timestamp'] + pd.Timedelta(hours=8)\n",
    "    ml1_df = ml1_df.astype({'PCI': str, 'EARFCN': str})\n",
    "\n",
    "    # Read ml1 csv data\n",
    "    Cells = {}\n",
    "    PCell = []\n",
    "    SCell1, SCell2, SCell3 = [], [], []\n",
    "\n",
    "    hys = dt.timedelta(seconds=5)\n",
    "    start_time = time_range[0] - hys\n",
    "    end_time = time_range[1] + hys\n",
    "\n",
    "    for i in range(len(ml1_df)):\n",
    "\n",
    "        t = ml1_df['Timestamp'].iloc[i]\n",
    "        if t < start_time: continue\n",
    "        elif start_time <= t < end_time: pass\n",
    "        elif end_time <= t: break\n",
    "\n",
    "        serv_cell_idx = ml1_df['Serving Cell Index'].iloc[i]\n",
    "        pci = ml1_df['PCI'].iloc[i]\n",
    "        earfcn = ml1_df['EARFCN'].iloc[i]\n",
    "        rsrp = ml1_df['RSRP(dBm)'].iloc[i]\n",
    "        rsrq = ml1_df['RSRQ(dB)'].iloc[i]\n",
    "\n",
    "        ss = SS(pci, earfcn, rsrp, rsrq, t)\n",
    "        \n",
    "        if serv_cell_idx == 'PCell':\n",
    "            PCell.append(ss)\n",
    "        elif serv_cell_idx == '1_SCell':\n",
    "            SCell1.append(ss)\n",
    "        elif serv_cell_idx == '2_SCell':\n",
    "            SCell2.append(ss)\n",
    "        elif serv_cell_idx == '(MI)Unknown':\n",
    "            SCell3.append(ss)\n",
    "\n",
    "        k = pci+' '+earfcn \n",
    "        if k in Cells.keys():\n",
    "            Cells[k].append(ss)\n",
    "        else:\n",
    "            Cells[k] = [ss]\n",
    "\n",
    "        # Cells\n",
    "        num_neicells = ml1_df['Number of Neighbor Cells'].iloc[i]\n",
    "        \n",
    "        for j in np.arange(9, 9+num_neicells*3,3):\n",
    "            pci = str(int(ml1_df.iloc[i][j]))\n",
    "            rsrp = ml1_df.iloc[i][j+1]\n",
    "            rsrq = ml1_df.iloc[i][j+2]\n",
    "            ss = SS(pci, earfcn, rsrp, rsrq, t)\n",
    "            k = pci+' '+earfcn \n",
    "\n",
    "            if k in Cells.keys():\n",
    "                Cells[k].append(ss)\n",
    "            else:\n",
    "                Cells[k] = [ss]\n",
    "    \n",
    "    return PCell, SCell1, SCell2, SCell3, Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NR RSRP/RSRQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = namedtuple('SS', ['PCI', 'earfcn', 'RSRP', 'RSRQ', 'Timestamp'], defaults=['','',0,0,None])\n",
    "\n",
    "def NR_signal_strength(ml1_file, time_range):\n",
    "    # Read csv with pandas\n",
    "    ml1_df = pd.read_csv(ml1_file)\n",
    "    ml1_df['Timestamp'] = pd.to_datetime(ml1_df['Timestamp'])\n",
    "    ml1_df['Timestamp'] = ml1_df['Timestamp'] + pd.Timedelta(hours=8)\n",
    "    ml1_df = ml1_df.astype({'Serving Cell PCI': str, 'Raster ARFCN': str})\n",
    "\n",
    "    Cells = {}\n",
    "    PSCell = []\n",
    "    \n",
    "    hys = dt.timedelta(seconds=5)\n",
    "    start_time = time_range[0] - hys\n",
    "    end_time = time_range[1] + hys\n",
    "\n",
    "    for i in range(len(ml1_df)):\n",
    "\n",
    "        t = ml1_df['Timestamp'].iloc[i]\n",
    "        if t < start_time: continue\n",
    "        elif start_time <= t < end_time: pass\n",
    "        elif end_time <= t: break\n",
    "\n",
    "        PSCell_pci = ml1_df['Serving Cell PCI'].iloc[i]\n",
    "        earfcn = ml1_df['Raster ARFCN'].iloc[i]\n",
    "\n",
    "        # Deal with Cells first        \n",
    "        for j in np.arange(6, len(ml1_df.columns),3):\n",
    "            if np.isnan(ml1_df.iloc[i][j]):\n",
    "                break\n",
    "            pci = str(int(ml1_df.iloc[i][j]))\n",
    "            rsrp = ml1_df.iloc[i][j+1]\n",
    "            rsrq = ml1_df.iloc[i][j+2]\n",
    "            ss = SS(pci, earfcn, rsrp, rsrq, t)\n",
    "            k = pci+' '+earfcn \n",
    "\n",
    "            if k in Cells.keys():\n",
    "                Cells[k].append(ss)\n",
    "            else:\n",
    "                Cells[k] = [ss]\n",
    "\n",
    "        # Deal with PSCell\n",
    "        if PSCell_pci == '65535':\n",
    "            continue\n",
    "        ss = Cells[PSCell_pci+' '+earfcn][-1]\n",
    "        PSCell.append(ss)\n",
    "        \n",
    "    \n",
    "    return PSCell, Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of files\n",
    "date = '2023-12-26'\n",
    "exp = 'Modem_Action_Test_v2_1'\n",
    "trace = '#02'\n",
    "\n",
    "base_dir = '/home/wmnlab/D/database'\n",
    "date_dir = os.path.join(base_dir, date)\n",
    "d = os.path.join(date_dir, exp)\n",
    "devs = sorted([a for a in os.listdir(d) if ('qc' in a or 'sm' in a)])\n",
    "data_dir1 = os.path.join(d, devs[0], trace, 'data')\n",
    "data_dir2 = os.path.join(d, devs[1], trace, 'data')\n",
    "rrc_file1 = [os.path.join(data_dir1, f) for f in os.listdir(data_dir1) if 'rrc' in f][0]\n",
    "rrc_file2 = [os.path.join(data_dir2, f) for f in os.listdir(data_dir2) if 'rrc' in f][0]\n",
    "ml1_file1 = [os.path.join(data_dir1, f) for f in os.listdir(data_dir1) if ('ml1' in f and not 'nr_ml1' in f)][0]\n",
    "ml1_file2 = [os.path.join(data_dir2, f) for f in os.listdir(data_dir2) if ('ml1' in f and not 'nr_ml1' in f)][0]\n",
    "nr_ml1_file1 = [os.path.join(data_dir1, f) for f in os.listdir(data_dir1) if 'nr_ml1' in f][0]\n",
    "nr_ml1_file2 = [os.path.join(data_dir2, f) for f in os.listdir(data_dir2) if 'nr_ml1' in f][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrc_file1, rrc_file2, ml1_file1, ml1_file2, nr_ml1_file1, nr_ml1_file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOs = parse_mi_ho(rrc_file1)\n",
    "MRs = MeasureReport(rrc_file1)\n",
    "MRs = correct_MR_with_HO(MRs, HOs)\n",
    "mappings = map_MR_HO(MRs, HOs)\n",
    "ordered_HOs1 = print_trans(HOs, mappings=mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOs = parse_mi_ho(rrc_file2)\n",
    "MRs = MeasureReport(rrc_file2)\n",
    "MRs = correct_MR_with_HO(MRs, HOs)\n",
    "mappings = map_MR_HO(MRs, HOs)\n",
    "ordered_HOs2 = print_trans(HOs, mappings=mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_loss_excl_file1 = os.path.join(data_dir1, 'udp_dnlk_loss_latency.csv')\n",
    "dl_loss_excl_file2 = os.path.join(data_dir2, 'udp_dnlk_loss_latency.csv')\n",
    "dl_loss1, dl_excl1 = loss_excl_cause(dl_loss_excl_file1, rrc_file1)\n",
    "dl_loss2, dl_excl2 = loss_excl_cause(dl_loss_excl_file2, rrc_file2)\n",
    "dl_loss, dl_excl = loss_excl_cause_dual(dl_loss_excl_file1, dl_loss_excl_file2, rrc_file1, rrc_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_loss_excl_file1 = os.path.join(data_dir1, 'udp_uplk_loss_latency.csv')\n",
    "ul_loss_excl_file2 = os.path.join(data_dir2, 'udp_uplk_loss_latency.csv')\n",
    "ul_loss1, ul_excl1 = loss_excl_cause(ul_loss_excl_file1, rrc_file1)\n",
    "ul_loss2, ul_excl2 = loss_excl_cause(ul_loss_excl_file2, rrc_file2)\n",
    "ul_loss, ul_excl = loss_excl_cause_dual(ul_loss_excl_file1, ul_loss_excl_file2, rrc_file1, rrc_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read time sync file\n",
    "time_sync_file = [os.path.join(date_dir, x) for x in os.listdir(date_dir) if x.endswith('.json') and 'time_sync' in x][0]\n",
    "print(time_sync_file)\n",
    "with open(time_sync_file, 'r') as f:\n",
    "    time_off_dict = json.load(f)\n",
    "\n",
    "pattern = r'(\\d{4}-\\d+-\\d+_\\d{2}-\\d{2}-\\d{2})'\n",
    "match = re.search(pattern, rrc_file1)\n",
    "if match:\n",
    "    datetime_str = match.group(1)\n",
    "    filetime = pd.to_datetime(datetime_str, format='%Y-%m-%d_%H-%M-%S')\n",
    "else:\n",
    "    print(\"File Name Error!\"); raise\n",
    "\n",
    "measure_times = [pd.to_datetime(k, format='%Y-%m-%d %H:%M:%S.%f') for k in time_off_dict.keys()]\n",
    "time_diffs = [abs(t-filetime) for t in measure_times]\n",
    "ind, value = min(enumerate(time_diffs), key=lambda x: x[1])\n",
    "print('rrc file time:', filetime,'; diff:',value)\n",
    "delta = dt.timedelta(seconds=list(time_off_dict.values())[ind])\n",
    "print('Sync Time:', list(time_off_dict.keys())[ind], '; delta',list(time_off_dict.values())[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_common_substring_length(str1, str2):\n",
    "    len1 = len(str1)\n",
    "    len2 = len(str2)\n",
    "\n",
    "    dp = [[0] * (len2 + 1) for _ in range(len1 + 1)]\n",
    "\n",
    "    max_length = 0  \n",
    "\n",
    "    for i in range(1, len1 + 1):\n",
    "        for j in range(1, len2 + 1):\n",
    "            if str1[i - 1] == str2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                max_length = max(max_length, dp[i][j])\n",
    "\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TimeSync csv\n",
    "dev_dir = os.path.join(date_dir, 'others/TimeSync', devs[0])\n",
    "files = os.listdir(dev_dir)\n",
    "value = max(files, key = lambda x: find_longest_common_substring_length(x, rrc_file1))\n",
    "ind = files.index(value)\n",
    "TimeSync_file1 = os.path.join(dev_dir, files[ind])\n",
    "\n",
    "dev_dir = os.path.join(date_dir, 'others/TimeSync', devs[1])\n",
    "files = os.listdir(dev_dir)\n",
    "value = max(files, key = lambda x: find_longest_common_substring_length(x, rrc_file2))\n",
    "ind = files.index(value)\n",
    "TimeSync_file2 = os.path.join(dev_dir, files[ind])\n",
    "\n",
    "print(rrc_file1, TimeSync_file1, rrc_file2, TimeSync_file2, sep='\\n')\n",
    "\n",
    "TS_df1 = pd.read_csv(TimeSync_file1)\n",
    "TS_df1['cell time'] = pd.to_datetime(TS_df1['cell time']) + dt.timedelta(hours=8)\n",
    "TS_df1['device time'] = pd.to_datetime(TS_df1['device time'])\n",
    "\n",
    "TS_df2 = pd.read_csv(TimeSync_file2)\n",
    "TS_df2['cell time'] = pd.to_datetime(TS_df2['cell time']) + dt.timedelta(hours=8)\n",
    "TS_df2['device time'] = pd.to_datetime(TS_df2['device time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions input ordered_HOs and output ordered_HOs with revised ho time align to server time \n",
    "def ho_time_to_server_time(ordered_HOs, TS_df):\n",
    "\n",
    "    HO = namedtuple('HO',['start', 'end', 'others', 'trans'], defaults=[None,None,'',''])\n",
    "\n",
    "    i = 0\n",
    "    ordered_HOs_ = []\n",
    "    for elements in ordered_HOs:\n",
    "        if len(elements) == 3:\n",
    "            Type, ho, mr = elements[0], elements[1], elements[2]\n",
    "        else:\n",
    "            Type, ho = elements[0], elements[1]\n",
    "\n",
    "        while i != len(TS_df)-1:\n",
    "            diff = (TS_df['cell time'].iloc[i]  - ho.start).total_seconds()\n",
    "            diff_ = (TS_df['cell time'].iloc[i+1]  - ho.start).total_seconds()\n",
    "            if abs(diff) < abs(diff_):\n",
    "                # device time + delta = server time; server time - cell time = server cell delta\n",
    "                server_cell_delta = TS_df['device time'].iloc[i] + delta - TS_df['cell time'].iloc[i]\n",
    "                ho_ = HO(start=ho.start+server_cell_delta, end=ho.end+server_cell_delta, others=ho.others, trans=ho.trans)\n",
    "                if len(elements) == 3:\n",
    "                    ordered_HOs_.append([Type, ho_, mr])\n",
    "                else:\n",
    "                    ordered_HOs_.append([Type, ho_])\n",
    "                break\n",
    "            i+=1\n",
    "    return ordered_HOs_\n",
    "\n",
    "# Functions input ordered_HOs and output ordered_HOs with revised ho time align to client time \n",
    "def ho_time_to_client_time(ordered_HOs, TS_df):\n",
    "\n",
    "    HO = namedtuple('HO',['start', 'end', 'others', 'trans'], defaults=[None,None,'',''])\n",
    "\n",
    "    i = 0\n",
    "    ordered_HOs_ = []\n",
    "    for elements in ordered_HOs:\n",
    "        if len(elements) == 3:\n",
    "            Type, ho, mr = elements[0], elements[1], elements[2]\n",
    "        else:\n",
    "            Type, ho = elements[0], elements[1]\n",
    "\n",
    "        while i != len(TS_df)-1:\n",
    "            diff = (TS_df['cell time'].iloc[i]  - ho.start).total_seconds()\n",
    "            diff_ = (TS_df['cell time'].iloc[i+1]  - ho.start).total_seconds()\n",
    "            if abs(diff) < abs(diff_):\n",
    "                # device time - cell time = client cell delta\n",
    "                client_cell_delta = TS_df['device time'].iloc[i] - TS_df['cell time'].iloc[i]\n",
    "                ho_ = HO(start=ho.start+client_cell_delta, end=ho.end+client_cell_delta, others=ho.others, trans=ho.trans)\n",
    "                if len(elements) == 3:\n",
    "                    ordered_HOs_.append([Type, ho_, mr])\n",
    "                else:\n",
    "                    ordered_HOs_.append([Type, ho_])\n",
    "                break\n",
    "            i+=1\n",
    "    return ordered_HOs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align ordered_HOs HO time to server time\n",
    "ordered_HOs1_ = ordered_HOs1 # store previous value\n",
    "ordered_HOs2_ = ordered_HOs2 # store previous value\n",
    "ordered_HOs1 = ho_time_to_server_time(ordered_HOs1, TS_df1)\n",
    "ordered_HOs2 = ho_time_to_server_time(ordered_HOs2, TS_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Functions\n",
    "def get_info(ordered_HOs, time_range):\n",
    "\n",
    "    T, Type, Trans, Ev = [], [], [], []\n",
    "    for element in ordered_HOs:\n",
    "        NO_MR = False\n",
    "        try:\n",
    "            type, ho, mr = element[0], element[1], element[2]\n",
    "        except:\n",
    "            type, ho = element[0], element[1]\n",
    "            NO_MR = True\n",
    "\n",
    "        if ho.start < time_range[0]:\n",
    "            continue\n",
    "        elif time_range[1] < ho.start:\n",
    "            break\n",
    "        else: # in time range\n",
    "            type = type.replace(\"_\", \" \")\n",
    "            \n",
    "            T.append(ho.start)\n",
    "            Type.append(type)\n",
    "            Trans.append(ho.trans)\n",
    "            if NO_MR:\n",
    "                Ev.append(mr.event)\n",
    "            else:\n",
    "                Ev.append(None)\n",
    "    \n",
    "    return T, Type, Trans, Ev\n",
    "\n",
    "patterns = {\n",
    "    'eNB HO': r'\\((\\d+), (\\d+)\\) -> \\((\\d+), (\\d+)\\)',\n",
    "    'gNB HO': r'(\\d+) -> (\\d+)',\n",
    "    'gNB setup': r'O -> (\\d+)',\n",
    "    'gNB rel':r'\\((\\d+), (\\d+)\\) \\| (\\d+) -> O' \n",
    "    }\n",
    "def get_pci(string, type):\n",
    "    pattern = patterns[type]\n",
    "    match = re.match(pattern, string)\n",
    "\n",
    "    if match:\n",
    "        if type == 'eNB HO':\n",
    "            return f'{match.group(1)}\\u2192{match.group(3)}'\n",
    "        elif type == 'gNB HO':\n",
    "            return f'{match.group(1)}\\u2192{match.group(2)}'\n",
    "        elif type == 'gNB setup':\n",
    "            return f'{match.group(1)}'\n",
    "        elif type == 'gNB rel':\n",
    "            return f'{match.group(3)}\\u2192N/A'\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates\n",
    "\n",
    "# Choose Style\n",
    "# 'classic', 'ggplot', 'seaborn', 'Solarize_Light2', 'bmh', 'fivethirtyeight', 'dark_background', 'grayscale',  \n",
    "plt.style.use('default')\n",
    "\n",
    "start_time = dt.datetime(2023, 12, 26, 15, 28, 24, 000000)\n",
    "end_time = dt.datetime(2023, 12, 26, 15, 28, 29, 000000)\n",
    "time_range = (start_time, end_time)\n",
    "\n",
    "R1_PCell, R1_SCell1, R1_SCell2, R1_SCell3, R1_Cells = LTE_signal_strength(ml1_file1, time_range)\n",
    "R2_PCell, R2_SCell1, R2_SCell2, R2_SCell3, R2_Cells = LTE_signal_strength(ml1_file2, time_range)\n",
    "\n",
    "R1_PSCell, R1_NR_Cells = NR_signal_strength(nr_ml1_file1, time_range)\n",
    "R2_PSCell, R2_NR_Cells = NR_signal_strength(nr_ml1_file2, time_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions input ss output ss with revised time align to server time \n",
    "def ss_time_to_server_time(Cell, TS_df):\n",
    "    i = 0\n",
    "    Cell_ = []\n",
    "    for ss in Cell:\n",
    "    \n",
    "        while i != len(TS_df)-1:\n",
    "            \n",
    "            diff = (TS_df['cell time'].iloc[i]  - ss.Timestamp).total_seconds()\n",
    "            diff_ = (TS_df['cell time'].iloc[i+1]  - ss.Timestamp).total_seconds()\n",
    "            if abs(diff) < abs(diff_):\n",
    "                # device time + delta = server time; server time - cell time = server cell delta\n",
    "                server_cell_delta = TS_df['device time'].iloc[i] + delta - TS_df['cell time'].iloc[i]\n",
    "                ss_ = SS(PCI=ss.PCI, earfcn=ss.earfcn, RSRP=ss.RSRP, RSRQ=ss.RSRQ, Timestamp=ss.Timestamp+server_cell_delta)\n",
    "                Cell_.append(ss_)\n",
    "                break\n",
    "            i+=1\n",
    "    return Cell_\n",
    "\n",
    "# Use the first delta only\n",
    "def ss_time_to_server_time_way2(Cell, TS_df):\n",
    "    # Calculate delta for middle data\n",
    "    if len(Cell) == 0:\n",
    "        return []\n",
    "    ss = Cell[-1]\n",
    "    i = 0\n",
    "    while i != len(TS_df)-1:\n",
    "        diff = (TS_df['cell time'].iloc[i]  - ss.Timestamp).total_seconds()\n",
    "        diff_ = (TS_df['cell time'].iloc[i+1]  - ss.Timestamp).total_seconds()\n",
    "        if abs(diff) < abs(diff_):\n",
    "            # device time + delta = server time; server time - cell time = server cell delta\n",
    "            server_cell_delta = TS_df['device time'].iloc[i] + delta - TS_df['cell time'].iloc[i]\n",
    "            break\n",
    "        i+=1\n",
    "\n",
    "    Cell_ = []\n",
    "    for ss in Cell:\n",
    "        ss_ = SS(PCI=ss.PCI, earfcn=ss.earfcn, RSRP=ss.RSRP, RSRQ=ss.RSRQ, Timestamp=ss.Timestamp+server_cell_delta)\n",
    "        Cell_.append(ss_)\n",
    "        \n",
    "    return Cell_\n",
    "\n",
    "def add_nan(Cell, add=dt.timedelta(seconds=1)):\n",
    "    \n",
    "    L = []\n",
    "    for i in range(len(Cell)-1):\n",
    "        dif = (Cell[i+1].Timestamp - Cell[i].Timestamp).total_seconds()\n",
    "        L.append(Cell[i])\n",
    "        if dif > 1:\n",
    "            L.append(SS('', '', np.nan, np.nan, Cell[i].Timestamp+add))\n",
    "\n",
    "    return L\n",
    "\n",
    "def add_nan_pkg(pkgs, add=dt.timedelta(seconds=0.1)):\n",
    "    \n",
    "    L = []\n",
    "    for i in range(len(pkgs)-1):\n",
    "        dif = (pkgs[i+1].Timestamp - pkgs[i].Timestamp).total_seconds()\n",
    "        L.append(pkgs[i])\n",
    "        if dif > 0.2:\n",
    "            L.append(PKG(pkgs[i].Timestamp+add,0,np.nan))\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align SS time to server time\n",
    "R1_PCell_, R1_SCell1_, R1_SCell2_, R1_SCell3_, R1_Cells_ = R1_PCell, R1_SCell1, R1_SCell2, R1_SCell3, R1_Cells\n",
    "[R1_PCell, R1_SCell1, R1_SCell2, R1_SCell3] = [ss_time_to_server_time_way2(cell, TS_df1) for cell in [R1_PCell, R1_SCell1, R1_SCell2, R1_SCell3]]\n",
    "R1_PCell = add_nan(R1_PCell)\n",
    "R1_Cells = {k: ss_time_to_server_time(cell, TS_df1) for k, cell in R1_Cells.items()}\n",
    "\n",
    "R2_PCell_, R2_SCell1_, R2_SCell2_, R2_SCell3_, R2_Cells_ = R2_PCell, R2_SCell1, R2_SCell2, R2_SCell3, R2_Cells\n",
    "[R2_PCell, R2_SCell1, R2_SCell2, R2_SCell3] = [ss_time_to_server_time_way2(cell, TS_df2) for cell in [R2_PCell, R2_SCell1, R2_SCell2, R2_SCell3]]\n",
    "R2_Cells = {k: ss_time_to_server_time(cell, TS_df2) for k, cell in R2_Cells.items()}\n",
    "\n",
    "R1_PSCell_, R1_NR_Cells_ = R1_PSCell, R1_NR_Cells\n",
    "R1_PSCell = ss_time_to_server_time(R1_PSCell_, TS_df1)\n",
    "R1_NR_Cells ={k: ss_time_to_server_time(cell, TS_df1) for k, cell in R1_NR_Cells.items()}\n",
    "\n",
    "R2_PSCell_, R2_NR_Cells_ = R2_PSCell, R2_NR_Cells\n",
    "R2_PSCell = ss_time_to_server_time_way2(R2_PSCell_, TS_df2)\n",
    "R2_PSCell = add_nan(R2_PSCell)\n",
    "R2_NR_Cells ={k: ss_time_to_server_time(cell, TS_df2) for k, cell in R2_NR_Cells.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Latency\n",
    "R1_dl_pkgs = accumulate_packet(dl_loss_excl_file1,time_range)\n",
    "R1_dl_pkgs = add_nan_pkg(R1_dl_pkgs)\n",
    "R2_dl_pkgs = accumulate_packet(dl_loss_excl_file2,time_range)\n",
    "R2_dl_pkgs = add_nan_pkg(R2_dl_pkgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1, Type1, Trans1, Ev1 = get_info(ordered_HOs1, time_range)\n",
    "T2, Type2, Trans2, Ev2 = get_info(ordered_HOs2, time_range)\n",
    "\n",
    "fig, axes = plt.subplots(4,1,figsize=(10, 6), sharex=True) \n",
    "HO_SCA1 = axes[0].scatter(T1, [1] * len(T1), marker='*', color='b', s=100, zorder=3, label='R1 HO')\n",
    "HO_SCA2 = axes[0].scatter(T2, [1] * len(T2), marker='o', color='r', s=100, zorder=3, label='R2 HO')\n",
    "\n",
    "axes[0].axhline(y=1, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "for event, type, trans in zip(T1, Type1, Trans1):\n",
    "    if type in ['LTE HO', 'MN HO']:\n",
    "        # continue\n",
    "        trans = trans.split(' | ')[0]\n",
    "        text = type + '\\n' + get_pci(trans, 'eNB HO')\n",
    "    elif type in ['RLF II']:\n",
    "        trans = trans.split(' | ')[0]\n",
    "        text = type + '\\n' + get_pci(trans, 'eNB HO')\n",
    "    elif type == 'MN HO to eNB':\n",
    "        trans = trans.split(' | ')[0]\n",
    "        text = 'MN HO\\nto eNB'+ '\\n' + get_pci(trans, 'eNB HO')\n",
    "    elif type in ['SN HO']:\n",
    "        # continue\n",
    "        trans = trans.split(' | ')[1]\n",
    "        text = type + '\\n' + get_pci(trans, 'gNB HO')\n",
    "    elif type == 'SN setup':\n",
    "        continue\n",
    "        trans = trans.split(' | ')[1]\n",
    "        text = type + '\\n' + get_pci(trans, 'gNB setup')\n",
    "    elif type == 'Conn Req':\n",
    "        text = type + '\\n' + get_pci(trans, 'eNB HO')\n",
    "    elif type == 'SCG RLF':\n",
    "        continue\n",
    "        text = 'SCG\\nRLF'\n",
    "    elif type == 'SN Rel':\n",
    "        # continue\n",
    "        text = 'SN\\nRel' + '\\n' + get_pci(trans, 'gNB rel')\n",
    "    \n",
    "    axes[0].text(event, 1.01, text, ha='center', va='bottom', fontsize=8, color='b', zorder=3)\n",
    "\n",
    "shift = 0.01\n",
    "for event, type, trans in zip(T2, Type2, Trans2):\n",
    "    if type in ['LTE HO', 'MN HO']:\n",
    "        # continue\n",
    "        trans = trans.split(' | ')[0]\n",
    "        text = type + '\\n' + get_pci(trans, 'eNB HO')\n",
    "    elif type in ['RLF II']:\n",
    "        trans = trans.split(' | ')[0]\n",
    "        text = type + '\\n' + get_pci(trans, 'eNB HO')\n",
    "    elif type == 'RLF III':\n",
    "        text = type\n",
    "    elif type == 'MN HO to eNB':\n",
    "        # continue\n",
    "        trans = trans.split(' | ')[0]\n",
    "        text = 'MN HO\\nto eNB'+ '\\n' + get_pci(trans, 'eNB HO')\n",
    "    elif type in ['SN HO']:\n",
    "        # continue\n",
    "        trans = trans.split(' | ')[1]\n",
    "        text = type + '\\n' + get_pci(trans, 'gNB HO')\n",
    "    elif type == 'SN setup':\n",
    "        continue\n",
    "        trans = trans.split(' | ')[1]\n",
    "        text = type + '\\n' + get_pci(trans, 'gNB setup')\n",
    "    elif type == 'Conn Req':\n",
    "        # continue\n",
    "        text = type + '\\n' + get_pci(trans, 'eNB HO')\n",
    "    elif type == 'SCG RLF':\n",
    "        continue\n",
    "        text = 'SCG\\nRLF'\n",
    "    elif type == 'SN Rel':\n",
    "        continue\n",
    "        text = 'SN\\nRel' + '\\n' + get_pci(trans, 'gNB rel')\n",
    "        \n",
    "    # plt.text(event, 0.99, text, ha='center', va='top', fontsize=8, color='r', zorder=3)\n",
    "    axes[0].text(event, 0.99-abs(shift)/2-shift/2, text, ha='center', va='top', fontsize=8, color='r', zorder=3)\n",
    "    shift*=-1\n",
    "    \n",
    "# plt.title('Events of Radio1 & Radio2')\n",
    "\n",
    "axes[0].set_yticks([])\n",
    "axes[0].set_xlim((start_time, end_time))\n",
    "\n",
    "x_range = axes[0].get_xlim()\n",
    "x_range = [dates.num2date(n).replace(tzinfo=None) for n in x_range]\n",
    "y_range = axes[0].get_ylim()\n",
    "\n",
    "axes[0].text((x_range[1] - x_range[0])*1/2+x_range[0], (y_range[1] - y_range[0])*4.2/5+y_range[0],  \n",
    "        '5G Radio1', ha='center', va='center', fontsize=12, color='b', zorder=5)\n",
    "axes[0].text((x_range[1] - x_range[0])*1/2+x_range[0], (y_range[1] - y_range[0])*0.8/5+y_range[0], \n",
    "        '5G Radio2', ha='center', va='center', fontsize=12, color='r', zorder=5)\n",
    "\n",
    "L1 = [pkg.timestamp for pkg in dl_loss1]\n",
    "L2 = [pkg.timestamp for pkg in dl_loss2]\n",
    "DL_LOSS1 = axes[0].vlines(x=L1, ymin=1, ymax=y_range[1], alpha=1, zorder=2, colors='lightblue', label='R1 DL Loss')\n",
    "DL_LOSS2 = axes[0].vlines(x=L2, ymin= y_range[0], ymax=1, alpha=1, zorder=2, colors='lightpink', label='R2 DL Loss')\n",
    "\n",
    "# L3 = [pkg.timestamp for pkg in dl_excl1]\n",
    "# L4 = [pkg.timestamp for pkg in dl_excl2]\n",
    "# DL_EXCL1 = axes[0].vlines(x=L3, ymin=1, ymax=y_range[1], alpha=1, zorder=1, colors='lightgreen', label='R1 DL EXCL')\n",
    "# DL_EXCL2 = axes[0].vlines(x=L4, ymin=y_range[0], ymax=1, alpha=1, zorder=1, colors='gold', label='R2 DL EXCL')\n",
    "\n",
    "# plot latency\n",
    "R1_Lat = axes[1].plot([pkg.Timestamp for pkg in R1_dl_pkgs], [pkg.latency for pkg in R1_dl_pkgs], \n",
    "            zorder=1, label='R1 Latency', linestyle='-')[0]\n",
    "R2_Lat = axes[1].plot([pkg.Timestamp for pkg in R2_dl_pkgs], [pkg.latency for pkg in R2_dl_pkgs], \n",
    "            zorder=1, label='R2 Latency', linestyle='-')[0]\n",
    "axes[1].set_ylim([0,0.5])\n",
    "axes[1].set_ylabel('Latency\\n(sec)')\n",
    "\n",
    "# Add Signal Strength\n",
    "R1_PCell_RSRP_PLOT = axes[2].plot([ss.Timestamp for ss in R1_PCell], [ss.RSRP for ss in R1_PCell], \n",
    "                            zorder=1, label='R1 RSRP', linestyle='--', marker='.')[0]\n",
    "R2_PCell_RSRP_PLOT = axes[2].plot([ss.Timestamp for ss in R2_PCell], [ss.RSRP for ss in R2_PCell], \n",
    "                            zorder=1, label='R2 RSRP', linestyle='--', marker='.')[0]\n",
    "\n",
    "R1_PSCell_RSRP_PLOT = axes[2].plot([ss.Timestamp for ss in R1_PSCell], [ss.RSRP for ss in R1_PSCell], \n",
    "                            zorder=1, label='R1 NR RSRP', linestyle='--', marker='.')[0]\n",
    "R2_PSCell_RSRP_PLOT = axes[2].plot([ss.Timestamp for ss in R2_PSCell], [ss.RSRP for ss in R2_PSCell], \n",
    "                            zorder=1, label='R2 NR RSRP', linestyle='--', marker='.')[0]\n",
    "axes[2].set_ylabel('RSRP\\n(dBm)')\n",
    "\n",
    "R1_PCell_RSRQ_PLOT = axes[3].plot([ss.Timestamp for ss in R1_PCell], [ss.RSRQ for ss in R1_PCell], \n",
    "                            zorder=1, label='R1 RSRQ', linestyle='--', marker='.')[0]\n",
    "R2_PCell_RSRQ_PLOT = axes[3].plot([ss.Timestamp for ss in R2_PCell], [ss.RSRQ for ss in R2_PCell], \n",
    "                            zorder=1, label='R2 RSRQ', linestyle='--', marker='.')[0]\n",
    "\n",
    "R1_PSCell_RSRQ_PLOT = axes[3].plot([ss.Timestamp for ss in R1_PSCell], [ss.RSRQ for ss in R1_PSCell], \n",
    "                            zorder=1, label='R1 NR RSRQ', linestyle='--', marker='.')[0]\n",
    "R2_PSCell_RSRQ_PLOT = axes[3].plot([ss.Timestamp for ss in R2_PSCell], [ss.RSRQ for ss in R2_PSCell], \n",
    "                            zorder=1, label='R2 NR RSRQ', linestyle='--', marker='.')[0]\n",
    "axes[3].set_ylabel('RSRQ\\n(dB)')\n",
    "\n",
    "# Legend\n",
    "# ax.legend(handles = [LOSS1, LOSS2], loc='upper right', bbox_to_anchor=(1.25, 1))\n",
    "axes[0].legend(handles = [DL_LOSS1, DL_LOSS2, HO_SCA1, HO_SCA2], loc='upper right', bbox_to_anchor=(1.20, 1.1))\n",
    "axes[1].legend(loc='upper right',  bbox_to_anchor=(1.20, 1.1))\n",
    "axes[2].legend(loc='upper right',  bbox_to_anchor=(1.20, 1.1))\n",
    "axes[3].legend(loc='upper right',  bbox_to_anchor=(1.20, 1.1))\n",
    "\n",
    "axes[-1].set_xlabel('Time')\n",
    "# axes[0].get_shared_x_axes().join(axes[0], axes[1])\n",
    "\n",
    "\n",
    "myFmt = mdates.DateFormatter('%H:%M:%S') # fmt %H:%M:%S.%f\n",
    "# axes[-1].xaxis.set_major_formatter(myFmt)\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
