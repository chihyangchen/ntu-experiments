{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import dates\n",
    "import matplotlib.pyplot as plt\n",
    "# Choose Style\n",
    "# 'classic', 'ggplot', 'seaborn', 'Solarize_Light2', 'bmh', 'fivethirtyeight', 'dark_background', 'grayscale',  \n",
    "plt.style.use('default')\n",
    "\n",
    "from utils import *\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_files = [\n",
    "    # '/home/wmnlab/D/database/2023-08-29/2023-08-29.md', \n",
    "    # '/home/wmnlab/D/database/2023-09-12-1/2023-09-12-1.md',\n",
    "    # '/home/wmnlab/D/database/2023-09-22/2023-09-22.md',\n",
    "    # '/home/wmnlab/D/database/2023-10-24/2023-10-24.md',\n",
    "    # '/home/wmnlab/D/database/2023-11-21/2023-11-21.md',\n",
    "    # '/home/wmnlab/D/database/2023-12-26/2023-12-26.md',\n",
    "    # '/home/wmnlab/D/database/2024-03-10/2024-03-10.md',\n",
    "    # '/home/wmnlab/D/database/2024-03-16/2024-03-16.md',\n",
    "    # '/home/wmnlab/E/database/2024-04-18/2024-04-18.md',\n",
    "    # '/home/wmnlab/E/database/2024-05-08/2024-05-08.md',\n",
    "    '/home/wmnlab/E/database/2024-05-20/2024-05-20.md'\n",
    "    ]\n",
    "\n",
    "EXPs = get_EXPs(md_files)\n",
    "pprint(EXPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Average $t_{cmd}$ to RRC reconnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "\n",
    "for exp in tqdm(EXPs):\n",
    "    if exp.type not in ['Modem_Action_Test_v6_A']:\n",
    "        continue\n",
    "    dev_dir_list = find_device_under_exp(exp.path)\n",
    "    [dev1, dev2] = list(exp.settings.keys())\n",
    "    dev_dir_list1 = [d for d in dev_dir_list if dev1 in d]\n",
    "    dev_dir_list2 = [d for d in dev_dir_list if dev2 in d]\n",
    "    dev_dir_path1 = dev_dir_list1[0]\n",
    "    dev_dir_path2 = dev_dir_list2[0]\n",
    "    \n",
    "    date_dir = '/'.join(exp.path.split('/')[:-1])\n",
    "    t_cmd_dir = os.path.join(date_dir, 'others/command_Time')\n",
    "    t_cmd_files = sorted([os.path.join(date_dir,  'others/command_Time', x)  for x in os.listdir(t_cmd_dir)])\n",
    "    with open(os.path.join(date_dir, 'sync/time_sync_lpt3.json'),'r') as f:\n",
    "        deltas = json.load(f)\n",
    "\n",
    "    trace_dir_list1 = find_trace_under_device(dev_dir_path1)\n",
    "    trace_dir_list2 = find_trace_under_device(dev_dir_path2)\n",
    "    for t_num, (t1, t2, cmd_file) in tqdm(enumerate(zip(trace_dir_list1, trace_dir_list2, t_cmd_files)), leave=False):\n",
    "        rrc1, rrc2 = return_rrc(t1), return_rrc(t2)\n",
    "        HOs1, HOs2 = parse_mi_ho(rrc1), parse_mi_ho(rrc2)\n",
    "        t_cmd_df = pd.read_csv(cmd_file)\n",
    "        delta = list(deltas.values())[t_num]\n",
    "        j, k = 0, 0\n",
    "        # pprint(HOs1['Action'])\n",
    "        # pprint(HOs2['Action'])\n",
    "        # pprint(delta)\n",
    "        for i in range(len(t_cmd_df)):\n",
    "            = t_cmd_df['R1'].iloc[i]\n",
    "            r2 = t_cmd_df['R2'].iloc[i]\n",
    "            if == 'action':\n",
    "                ts = dt.datetime.strptime(t_cmd_df['Timestamp'].iloc[i], '%Y-%m-%d %H:%M:%S.%f')\n",
    "                ts += dt.timedelta(seconds=delta)\n",
    "                diff = (HOs1['Action'][j].start - ts).total_seconds()\n",
    "                print('r1', ts, HOs1['Action'][j].start, diff)\n",
    "                j+=1\n",
    "                diffs.append(diff)\n",
    "            elif r2 == 'action':\n",
    "                ts = dt.datetime.strptime(t_cmd_df['Timestamp'].iloc[i], '%Y-%m-%d %H:%M:%S.%f')\n",
    "                ts += dt.timedelta(seconds=delta)\n",
    "                diff = (HOs2['Action'][k].start - ts).total_seconds()\n",
    "                print('r2', ts, HOs2['Action'][k].start, diff)\n",
    "                k+=1\n",
    "                diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = [d for d in diffs if d < 6]\n",
    "np.average(diffs), max(diffs), min(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Max Model Action Frequency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Why select the bad choice and what is the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_times = []\n",
    "action_exe_times = []\n",
    "too_late = 0\n",
    "bad_choice = 0\n",
    "for exp in tqdm(EXPs):\n",
    "    if exp.type not in ['Modem_Action_Test_v6_A']:\n",
    "        continue\n",
    "    dev_dir_list = find_device_under_exp(exp.path)\n",
    "    [dev1, dev2] = list(exp.settings.keys())\n",
    "    dev_dir_list1 = [d for d in dev_dir_list if dev1 in d]\n",
    "    dev_dir_list2 = [d for d in dev_dir_list if dev2 in d]\n",
    "    dev_dir_path1 = dev_dir_list1[0]\n",
    "    dev_dir_path2 = dev_dir_list2[0]\n",
    "    \n",
    "    date_dir = '/'.join(exp.path.split('/')[:-1])\n",
    "    t_cmd_dir = os.path.join(date_dir, 'others/command_Time')\n",
    "    t_cmd_files = sorted([os.path.join(date_dir,  'others/command_Time', x)  for x in os.listdir(t_cmd_dir)])\n",
    "    with open(os.path.join(date_dir, 'sync/time_sync_lpt3.json'),'r') as f:\n",
    "        deltas = json.load(f)\n",
    "\n",
    "    trace_dir_list1 = find_trace_under_device(dev_dir_path1)\n",
    "    trace_dir_list2 = find_trace_under_device(dev_dir_path2)\n",
    "    for t_num, (t1, t2, cmd_file) in tqdm(enumerate(zip(trace_dir_list1, trace_dir_list2, t_cmd_files)), leave=False):\n",
    "        rrc1, rrc2 = return_rrc(t1), return_rrc(t2)\n",
    "        HOs1, HOs2 = parse_mi_ho(rrc1), parse_mi_ho(rrc2)\n",
    "        t_cmd_df = pd.read_csv(cmd_file)\n",
    "        delta = list(deltas.values())[t_num]\n",
    "\n",
    "        print(f'Actions {t_num+1}')\n",
    "        pprint(HOs1['Conn_Req'])\n",
    "        pprint(HOs2['Conn_Req'])\n",
    "        \n",
    "        print('RLF')\n",
    "        pprint(HOs1['RLF_II']+HOs1['RLF_III'])\n",
    "        pprint(HOs2['RLF_II']+HOs2['RLF_III'])\n",
    "        print('Start...')\n",
    "        j, k = 0, 0\n",
    "        pre_action1, pre_action2 = None, None\n",
    "\n",
    "        for i in range(len(t_cmd_df)):\n",
    "            '= t_cmd_df['R1'].iloc[i]\n",
    "            r2 = t_cmd_df['R2'].iloc[i]\n",
    "            \n",
    "            if == 'action':\n",
    "                action_time = HOs1['Conn_Req'][j].start\n",
    "                action_exe_times.append( (HOs1['Conn_Req'][j].end - HOs1['Conn_Req'][j].start).total_seconds() )\n",
    "                j+=1\n",
    "                for enb_ho in HOs1['LTE_HO'] + HOs1['MN_HO'] + HOs1['MN_HO_to_eNB']:\n",
    "                    enb_ho_time = enb_ho.start \n",
    "                    if 0 < (action_time - enb_ho_time).total_seconds() < 2: # case too late\n",
    "                        print('too late1')\n",
    "                        too_late+=1\n",
    "\n",
    "                for rlf in HOs1['RLF_II']+HOs1['RLF_III']:\n",
    "                    rlf_time = rlf.start \n",
    "                    if 0 < (action_time - rlf_time).total_seconds() < 3: # case too late\n",
    "                        print('too late2')\n",
    "                        too_late+=1\n",
    "                    elif 0 < (rlf_time - action_time).total_seconds() < 6: # case bad choice\n",
    "                        print('bad choice1', action_time)\n",
    "                        bad_choice+=1\n",
    "                \n",
    "                if pre_action1 is not None and 0 < (action_time - pre_action1).total_seconds() < 8:\n",
    "                    print('bad choice2', action_time)\n",
    "                    bad_choice+=1\n",
    "                pre_action1 = action_time\n",
    "                action_times.append(action_time)\n",
    "\n",
    "            elif r2 == 'action':\n",
    "                action_time = HOs2['Conn_Req'][k].start\n",
    "                action_exe_times.append( (HOs2['Conn_Req'][k].end - HOs2['Conn_Req'][k].start).total_seconds() )\n",
    "                k+=1\n",
    "                for enb_ho in HOs2['LTE_HO'] + HOs2['MN_HO'] + HOs2['MN_HO_to_eNB']:\n",
    "                    enb_ho_time = enb_ho.start \n",
    "                    if 0 < (action_time - enb_ho_time).total_seconds() < 1: # case too late\n",
    "                        print('too late1')\n",
    "                        too_late+=1\n",
    "\n",
    "                for rlf in HOs2['RLF_II']+HOs2['RLF_III']:\n",
    "                    rlf_time = rlf.start\n",
    "                    if 0 < (action_time - rlf_time).total_seconds() < 3:\n",
    "                        print('too late2')\n",
    "                        too_late+=1\n",
    "                    elif 0 < (rlf_time - action_time).total_seconds() < 6: # case bad choice\n",
    "                        print('bad choice1', action_time)\n",
    "                        bad_choice+=1\n",
    "                \n",
    "                if pre_action2 is not None and 0 < (action_time - pre_action2).total_seconds() < 8:\n",
    "                    print('bad choice2', action_time)\n",
    "                    bad_choice+=1\n",
    "                pre_action2 = action_time\n",
    "                action_times.append(action_time)\n",
    "\n",
    "        print('========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(action_times), too_late , bad_choice, np.average(action_exe_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Performance difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['DL Loss','DL Excl','UL Loss','UL Excl']\n",
    "CG5 = {k:[] for k in keys}\n",
    "v6 = {k:[] for k in keys}\n",
    "\n",
    "def exp_append(exp, metrics):\n",
    "    for k, v in zip(keys, metrics):\n",
    "        exp[k].append(v)\n",
    "\n",
    "for exp in tqdm(EXPs):\n",
    "    if exp.type not in ['Modem_Action_Test_v6_A', 'Control_Group5']:\n",
    "        continue\n",
    "    dev_dir_list = find_device_under_exp(exp.path)\n",
    "    [dev1, dev2] = list(exp.settings.keys())\n",
    "    dev_dir_list1 = [d for d in dev_dir_list if dev1 in d]\n",
    "    dev_dir_list2 = [d for d in dev_dir_list if dev2 in d]\n",
    "    dev_dir_path1 = dev_dir_list1[0]\n",
    "    dev_dir_path2 = dev_dir_list2[0]\n",
    "    \n",
    "    date_dir = '/'.join(exp.path.split('/')[:-1])\n",
    "    t_cmd_dir = os.path.join(date_dir, 'others/command_Time')\n",
    "    t_cmd_files = sorted([os.path.join(date_dir,  'others/command_Time', x)  for x in os.listdir(t_cmd_dir)])\n",
    "    with open(os.path.join(date_dir, 'sync/time_sync_lpt3.json'),'r') as f:\n",
    "        deltas = json.load(f)\n",
    "\n",
    "    trace_dir_list1 = find_trace_under_device(dev_dir_path1)\n",
    "    trace_dir_list2 = find_trace_under_device(dev_dir_path2)\n",
    "    for t_num, (t1, t2, cmd_file) in tqdm(enumerate(zip(trace_dir_list1, trace_dir_list2, t_cmd_files)), leave=False):\n",
    "        rrc1, rrc2 = return_rrc(t1), return_rrc(t2)\n",
    "        DL1, DL2 = return_DL(t1), return_DL(t2)\n",
    "        UL1, UL2 = return_UL(t1), return_UL(t2)\n",
    "\n",
    "        # dl_loss, dl_excl = count_loss_excl_rate_dual(DL1, DL2)\n",
    "        # ul_loss, ul_excl = count_loss_excl_rate_dual(UL1, UL2)\n",
    "        # metrics = [dl_loss*100, dl_excl*100, ul_loss*100, ul_excl*100]\n",
    "        \n",
    "        dl_loss_pkg_duals, dl_excl_pkg_duals = loss_excl_cause_dual(DL1, DL2, rrc1, rrc2)\n",
    "        ul_loss_pkg_duals, ul_excl_pkg_duals = loss_excl_cause_dual(UL1, UL2, rrc1, rrc2)\n",
    "        \n",
    "        if exp.type == 'Control_Group5':\n",
    "            exp_append(CG5, [dl_loss_pkg_duals, dl_excl_pkg_duals, ul_loss_pkg_duals, ul_excl_pkg_duals] )\n",
    "        elif exp.type == 'Modem_Action_Test_v6_A':\n",
    "            exp_append(v6, [dl_loss_pkg_duals, dl_excl_pkg_duals, ul_loss_pkg_duals, ul_excl_pkg_duals] )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause = {}\n",
    "total_pkg = 0\n",
    "\n",
    "custom_order = {'Conn_Req': 1, \n",
    "                'RLF_III': 2, \n",
    "                'RLF_II':3, \n",
    "                'SCG_RLF':4, \n",
    "                'MN_HO':5,\n",
    "                'MN_HO_to_eNB':6,\n",
    "                'SN_HO':7,\n",
    "                'LTE_HO':8,\n",
    "                'SN_setup':9,\n",
    "                'SN_Rel':10}\n",
    "\n",
    "for L in CG5['DL Excl']:\n",
    "    for dual_pkg in L:\n",
    "        total_pkg+=1\n",
    "\n",
    "        cause1 = [c.split(' ')[-1] for c in dual_pkg.cause1]\n",
    "        trans1 = dual_pkg.trans1\n",
    "        cause2 = [c.split(' ')[-1] for c in dual_pkg.cause2]\n",
    "        trans2 = dual_pkg.trans2\n",
    "        if len(cause1)==0 and len(cause1)==0:\n",
    "            continue\n",
    "        elif len(cause1)==0:\n",
    "            zipped_lists2 = zip(cause2, trans2)\n",
    "            sorted_zipped_lists2 = sorted(zipped_lists2, key=lambda x: custom_order[x[0]])  \n",
    "            cause2, trans2 = zip(*sorted_zipped_lists2)\n",
    "            for c2, trans2 in zip(cause2, trans2):\n",
    "                k = f'stable+{c2}'\n",
    "                if k in cause.keys(): cause[k]+=1\n",
    "                else: cause[k]=1\n",
    "                break\n",
    "            continue\n",
    "        elif len(cause2)==0:\n",
    "            zipped_lists1 = zip(cause1, trans1)\n",
    "            sorted_zipped_lists1 = sorted(zipped_lists1, key=lambda x: custom_order[x[0]])  \n",
    "            cause1, trans1 = zip(*sorted_zipped_lists1)\n",
    "            for c1, trans1 in zip(cause1, trans1):\n",
    "                k = f'{c1}+stable'\n",
    "                if k in cause.keys(): cause[k]+=1\n",
    "                else: cause[k]=1\n",
    "                break\n",
    "            continue\n",
    "        zipped_lists1 = zip(cause1, trans1)\n",
    "        sorted_zipped_lists1 = sorted(zipped_lists1, key=lambda x: custom_order[x[0]])  \n",
    "        cause1, trans1 = zip(*sorted_zipped_lists1)\n",
    "        zipped_lists2 = zip(cause2, trans2)\n",
    "        sorted_zipped_lists2 = sorted(zipped_lists2, key=lambda x: custom_order[x[0]])  \n",
    "        cause2, trans2 = zip(*sorted_zipped_lists2)\n",
    "        for c1, trans1 in zip(cause1,trans1):\n",
    "            pci1 = get_pci_from_HO_type(trans1, c1)\n",
    "            for c2, trans2 in zip(cause2, trans2):\n",
    "                pci2 = get_pci_from_HO_type(trans2, c2)\n",
    "                k = f'{c1}+{c2}'\n",
    "                if pci1==pci2:\n",
    "                    k+=' *'\n",
    "                if k in cause.keys(): cause[k]+=1\n",
    "                else: cause[k]=1\n",
    "                break\n",
    "            break\n",
    "            \n",
    "sorted_dict_by_key = dict(sorted(cause.items(), key=lambda item: -item[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_dict_by_key, total_pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG5_loss = {'RLF_II+RLF_II *': 830} # Total 830\n",
    "# Total 758\n",
    "CG6_Excl = {'RLF_II+LTE_HO': 471,\n",
    "            'MN_HO+LTE_HO': 123,\n",
    "            'SN_HO+stable': 100,\n",
    "            'SN_HO+LTE_HO': 17,\n",
    "            'RLF_II+RLF_II *': 17,\n",
    "            'MN_HO+LTE_HO *': 12,\n",
    "            'RLF_II+LTE_HO *': 7,\n",
    "            'SN_HO+LTE_HO *': 6,\n",
    "            'MN_HO_to_eNB+LTE_HO *': 5}\n",
    "\n",
    "v6_loss = {'RLF_II+Action *': 790} # Total 790\n",
    "v6_Excl = {'RLF_II+Action *': 358, # Total 774\n",
    "           'Action+LTE_HO': 143,\n",
    "           'MN_HO+Action': 79,\n",
    "           'SN_HO+LTE_HO *': 57,\n",
    "           'Action+LTE_HO *': 53,\n",
    "           'Action+stable': 51,\n",
    "           'MN_HO_to_eNB+Action *': 33}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = list(v6_Excl.values())\n",
    "lab = [a.replace(\"_\", \" \") for a in list(v6_Excl.keys())]\n",
    "val.reverse(), lab.reverse()\n",
    "total = 774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建橫條圖\n",
    "fig, ax = plt.subplots()\n",
    "plt.barh(lab, val, color='skyblue')\n",
    "for i, v in enumerate(x):\n",
    "    plt.text(v, i, f'{v/total*100:.2f}%')\n",
    "plt.xlabel('Number of Package (* means having same pci)',weight='bold')\n",
    "plt.title('Handover Event Pairs vs. Downlink Excessive Latency',weight='bold')\n",
    "# plt.tight_layout()\n",
    "plt.ylabel('R1 HO+R2 HO', rotation=0, weight='bold')\n",
    "ax.yaxis.set_label_coords(-0.13, 0.98)\n",
    "# 顯示圖表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG5_loss = {'RLF_II+RLF_II *': 830} # Total 830\n",
    "v6_loss = {'RLF_II+Action *': 790} # Total 790\n",
    "lab = ['B1B8+LTE\\nRLF_II+RLF_II *', 'DBL\\nRLF_II+Action *']\n",
    "val = list(CG5_loss.values())+list(v6_loss.values())\n",
    "x = [0.2,0.5]\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "plt.bar(x, val, width=0.15, align='center')\n",
    "plt.xticks(x, lab)\n",
    "plt.ylabel('Number of package',weight='bold')\n",
    "plt.xlabel('(* means same pci)',weight='bold')\n",
    "plt.title('DL Loss Casue of two Scheme', weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/wmnlab/E/database'\n",
    "date = '2024-05-20'\n",
    "exp = 'Modem_Action_Test_v6_A'\n",
    "trace = '#09'\n",
    "\n",
    "date_dir = os.path.join(base_dir, date)\n",
    "d = os.path.join(date_dir, exp)\n",
    "devs = sorted([a for a in os.listdir(d) if ('qc' in a or 'sm' in a)])\n",
    "data_dirs = [os.path.join(d, dev, trace, 'data') for dev in devs]\n",
    "rrc_files = [[os.path.join(data_dir, f) for f in os.listdir(data_dir) if 'rrc' in f][0] for data_dir in data_dirs]\n",
    "ml1_files = [[os.path.join(data_dir, f) for f in os.listdir(data_dir) if ('ml1' in f and not 'nr_ml1' in f)][0] for data_dir in data_dirs]\n",
    "nr_ml1_files = [[os.path.join(data_dir, f) for f in os.listdir(data_dir) if 'nr_ml1' in f][0] for data_dir in data_dirs]\n",
    "dl_loss_excl_files = [os.path.join(data_dir, 'udp_dnlk_loss_latency.csv') for data_dir in data_dirs]\n",
    "ul_loss_excl_files = [os.path.join(data_dir, 'udp_uplk_loss_latency.csv') for data_dir in data_dirs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_HOs_list = [to_ordered_HO(f) for f in rrc_files]\n",
    "dl_loss_ecxl_pkgs = [loss_excl_cause(dl, rrc) for dl, rrc in zip(dl_loss_excl_files, rrc_files)]\n",
    "ul_loss_ecxl_pkgs = [loss_excl_cause(ul, rrc) for ul, rrc in zip(ul_loss_excl_files, rrc_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_loss1, dl_excl1 = loss_excl_cause_dual(dl_loss_excl_files[0], dl_loss_excl_files[1], rrc_files[0], rrc_files[1])\n",
    "dl_loss2, dl_excl2 = loss_excl_cause_dual(dl_loss_excl_files[2], dl_loss_excl_files[3], rrc_files[2], rrc_files[3])\n",
    "len(dl_loss1), len(dl_excl1), len(dl_loss2), len(dl_excl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = dt.datetime(2024, 5, 20, 16, 44, 30, 000000)\n",
    "end_time = dt.datetime(2024, 5, 20, 16, 44, 37, 000000)\n",
    "time_range = (start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = []\n",
    "for ordered_HOs in ordered_HOs_list:\n",
    "    T, Type, Trans, Ev = get_info(ordered_HOs, time_range)\n",
    "    elements.append( (T, Type, Trans, Ev) )\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True) \n",
    "HO_SCAs = []\n",
    "\n",
    "labels = ['HO (CG5)', 'HO (CG5)', 'R1 HO (DBL)', 'R2 HO (DBL)']\n",
    "colors = ['r', 'b'] * 2\n",
    "for element, label, c in zip(elements, labels, colors):\n",
    "    (T, Type, Trans, Ev) = element\n",
    "    i = 0 if 'CG5' in label else 1\n",
    "    HO_SCA = axes[i].scatter(T, [1] * len(T), marker='*', color=c, s=100, zorder=3, label=label)\n",
    "    HO_SCAs.append(HO_SCA)\n",
    "\n",
    "    pos = 1.1 if 'R1' in label else 0.65\n",
    "    for event, type, trans in zip(T, Type, Trans):                          \n",
    "        if type in ['LTE HO', 'MN HO']:\n",
    "            trans = trans.split(' | ')[0]\n",
    "            text = type + '\\n' + get_pci(trans, 'eNB HO')\n",
    "        elif type in ['RLF II']:\n",
    "            trans = trans.split(' | ')[0]\n",
    "            text = type + '\\n' + get_pci(trans, 'eNB HO')\n",
    "        elif type == 'MN HO to eNB':\n",
    "            trans = trans.split(' | ')[0]\n",
    "            text = 'MN HO\\nto eNB'+ '\\n' + get_pci(trans, 'eNB HO')\n",
    "        elif type in ['SN HO']:\n",
    "            trans = trans.split(' | ')[1]\n",
    "            text = type + '\\n' + get_pci(trans, 'gNB HO')\n",
    "        elif type == 'SN setup':\n",
    "            trans = trans.split(' | ')[1]\n",
    "            text = type + '\\n' + get_pci(trans, 'gNB setup')\n",
    "        elif type == 'Conn Req':\n",
    "            text = type + '\\n' + get_pci(trans, 'eNB HO')\n",
    "        elif type == 'SCG RLF':\n",
    "            text = 'SCG\\nRLF'\n",
    "        elif type == 'SN Rel':\n",
    "            text = 'SN\\nRel' + '\\n' + get_pci(trans, 'gNB rel')\n",
    "        \n",
    "        axes[i].text(event, pos, text, ha='center', va='bottom', fontsize=8, color=c, zorder=3)\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i].axhline(y=1, color='gray', linestyle='--', linewidth=1)\n",
    "    axes[i].set_yticks([])\n",
    "    axes[i].set_ylim([0,2])\n",
    "    axes[i].set_xlim((start_time, end_time))\n",
    "\n",
    "DL_Losses = []\n",
    "DL_Excls = []\n",
    "labels = ['R1 Loss (CG5)', 'R2 Loss (CG5)', 'R1 Loss (DBL)', 'R2 Loss (DBL)']\n",
    "labels2 = ['R1 Excl (CG5)', 'R2 Excl (CG5)', 'R1 Excl (DBL)', 'R2 Excl (DBL)']\n",
    "colors = ['lightblue', 'lightpink'] * 2; colors2 = ['lightgreen', 'gold'] * 2\n",
    "y_range = axes[0].get_ylim()\n",
    "for (loss, excl), lab, lab2, c, c2 in zip(dl_loss_ecxl_pkgs, labels, labels2, colors, colors2):\n",
    "    L = [pkg.timestamp for pkg in loss]; L2 = [pkg.timestamp for pkg in excl]\n",
    "    a,b = (1, y_range[1]) if 'R1' in lab else (y_range[0], 1)\n",
    "    i = 0 if 'CG5' in lab else 1\n",
    "    DL_LOSS = axes[i].vlines(x=L, ymin=a, ymax=b, alpha=1, zorder=2, colors=c, label=lab)\n",
    "    DL_EXCL = axes[i].vlines(x=L2, ymin=a, ymax=b, alpha=1, zorder=1, colors=c2, label=lab2)\n",
    "    DL_Losses.append(DL_LOSS)\n",
    "    DL_Excls.append(DL_EXCL)\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i].legend(loc='upper right',  bbox_to_anchor=(1.20, 1.1))\n",
    "\n",
    "myFmt = dates.DateFormatter('%H:%M:%S') # fmt %H:%M:%S.%f\n",
    "axes[-1].xaxis.set_major_formatter(myFmt)\n",
    "axes[-1].set_xlabel('Time')\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
