{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import swifter\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files\n",
    "# This function input the path of experiment directory and output a list of device directories of the experiment directory.\n",
    "def find_device_under_exp(exp_dir_path):\n",
    "    dev_dir_list = sorted([os.path.join(exp_dir_path, d) for d in os.listdir(exp_dir_path) if d.startswith('qc') or d.startswith('sm')])\n",
    "    return dev_dir_list\n",
    "\n",
    "def find_trace_under_device(dev_dir_path):\n",
    "    trace_dir_list = sorted([os.path.join(dev_dir_path, d) for d in os.listdir(dev_dir_path)])\n",
    "    return trace_dir_list\n",
    "\n",
    "\n",
    "# Convenience instance\n",
    "class EXPERIMENT():\n",
    "    def __init__(self, exp_dir_path, settings):\n",
    "        self.path = exp_dir_path\n",
    "        self.settings = json.loads(settings)\n",
    "    def __repr__(self):\n",
    "        return f'EXP: {self.path} -> {self.settings}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mi_ho(f):\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"Timestamp\"] = df[\"Timestamp\"].swifter.apply(lambda x: pd.to_datetime(x) + dt.timedelta(hours=8)) \n",
    "    nr_pci = 'O'\n",
    "    scells = []\n",
    "\n",
    "    def NR_OTA(idx):\n",
    "\n",
    "        if df[\"type_id\"].iloc[idx] == \"5G_NR_RRC_OTA_Packet\": return True\n",
    "        else: return False\n",
    "    \n",
    "    def LTE_SERV_INFO(idx):\n",
    "\n",
    "        if df[\"type_id\"].iloc[idx] == \"LTE_RRC_Serv_Cell_Info\": return True\n",
    "        else: return False\n",
    "    \n",
    "\n",
    "    def find_1st_after(start_idx, target, look_after=1):\n",
    "        for j in range(start_idx, len(df)):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "                continue\n",
    "            if (t_ - t).total_seconds() > look_after:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_1st_before(start_idx, target, look_before=1):\n",
    "        for j in range(start_idx, -1, -1):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "                continue\n",
    "            if (t - t_).total_seconds() > look_before:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_1st_before_with_special_value(start_idx, target, target_value, look_before=1):\n",
    "        for j in range(start_idx, -1, -1):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "                continue\n",
    "            if (t - t_).total_seconds() > look_before:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] in [target_value] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_in_D_exact(targets):\n",
    "\n",
    "        l = []\n",
    "        # In l : (second, ho_type)\n",
    "        for target in targets:\n",
    "            for ho in D[target]:\n",
    "                l.append(((t - ho.start).total_seconds(), target))\n",
    "\n",
    "        if len(l) != 0:\n",
    "            for x in l:\n",
    "                if (x[0]== 0):\n",
    "                    return x[1]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def find_in_D_first_before(targets, look_before=1):\n",
    "\n",
    "        l = []\n",
    "        # In l : (second, ho_type)\n",
    "        for target in targets:\n",
    "            for ho in D[target]:\n",
    "                l.append(((t - ho.end).total_seconds(), target, ho))\n",
    "\n",
    "        if len(l) != 0:\n",
    "            closest = min(filter(lambda x: x[0] > 0, l), key=lambda x: x[0])\n",
    "            if 0 <= closest[0] < look_before:\n",
    "                return closest[1], closest[2]\n",
    "        \n",
    "        return None, None\n",
    "\n",
    "    HO = namedtuple('HO',['start', 'end', 'others', 'trans'], defaults=[None,None,'',''])\n",
    "    \n",
    "    D = {\n",
    "        'Conn_Rel':[], \n",
    "        'Conn_Req':[], # Setup\n",
    "        'LTE_HO': [], # LTE -> newLTE\n",
    "        'MN_HO': [], # LTE + NR -> newLTE + NR\n",
    "        'MN_HO_to_eNB': [], # LTE + NR -> newLTE\n",
    "        'SN_setup': [], # LTE -> LTE + NR => NR setup\n",
    "        'SN_Rel': [], # LTE + NR -> LTE\n",
    "        'SN_HO': [], # LTE + NR -> LTE + newNR  \n",
    "        'RLF_II': [],\n",
    "        'RLF_III': [],\n",
    "        'SCG_RLF': [],\n",
    "        'Add_SCell': [],\n",
    "        }\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # Pass NR RRC packet. In NSA mode, LTE RRC packet include NR packet message.\n",
    "        if NR_OTA(i) or LTE_SERV_INFO(i):\n",
    "            continue\n",
    "\n",
    "        try: lte_pci, lte_earfcn\n",
    "        except: \n",
    "            lte_pci = df[\"PCI\"].iloc[i]\n",
    "            lte_earfcn = int(df[\"Freq\"].iloc[i])\n",
    "\n",
    "        others = ''\n",
    "        t = df[\"Timestamp\"].iloc[i]\n",
    "\n",
    "        if df[\"rrcConnectionRelease\"].iloc[i] == 1:\n",
    "            D['Conn_Rel'].append(HO(start=t))\n",
    "            nr_pci = 'O'\n",
    "\n",
    "        if df[\"rrcConnectionRequest\"].iloc[i] == 1:\n",
    "            \n",
    "            # Define end of rrcConnectionRequest to be rrcConnectionReconfigurationComplete or securityModeComplete.\n",
    "            a = find_1st_after(i, 'rrcConnectionReconfigurationComplete',look_after=2)[0]\n",
    "            b = find_1st_after(i, 'securityModeComplete',look_after=2)[0]\n",
    "        \n",
    "            if a is None and b is None: end = None\n",
    "            elif a is None and b is not None: end = b\n",
    "            elif a is not None and b is None: end = a \n",
    "            else: end = a if a > b else b\n",
    "            \n",
    "            _, idx = find_1st_after(i, 'ueCapabilityInformation',look_after=1)\n",
    "            if idx is not None:\n",
    "                sup_band = df['bandEUTRA'].iloc[idx]\n",
    "                others += f' supported band: {sup_band}.' \n",
    "\n",
    "            serv_cell, serv_freq = df[\"PCI\"].iloc[i], int(df[\"Freq\"].iloc[i])\n",
    "            trans = f'({lte_pci}, {lte_earfcn}) -> ({serv_cell}, {serv_freq})'\n",
    "            \n",
    "            # Check if caused by RLF III.\n",
    "            a, idx = find_1st_before(i, 'rrcConnectionReestablishmentReject', look_before=1)\n",
    "            if a is not None:\n",
    "                others += ' After RLF III.'\n",
    "\n",
    "            D['Conn_Req'].append(HO(start=t,end=end,trans=trans, others=others))\n",
    "\n",
    "            nr_pci = 'O'\n",
    "            lte_pci = serv_cell\n",
    "            lte_earfcn = serv_freq\n",
    "            \n",
    "        if df[\"lte-rrc.t304\"].iloc[i] == 1:\n",
    "            \n",
    "            end, _ = find_1st_after(i, 'rrcConnectionReconfigurationComplete')\n",
    "            serv_cell, target_cell = df[\"PCI\"].iloc[i], int(df['lte_targetPhysCellId'].iloc[i])\n",
    "            serv_freq, target_freq = int(df[\"Freq\"].iloc[i]), int(df['dl-CarrierFreq'].iloc[i])\n",
    "\n",
    "            lte_pci = target_cell\n",
    "            lte_earfcn = target_freq\n",
    "\n",
    "            if df[\"SCellToAddMod-r10\"].iloc[i] == 1:\n",
    "                n =len(str(df[\"SCellIndex-r10.1\"].iloc[i]).split('@'))\n",
    "                others += f' Set up {n} SCell.'\n",
    "            else:\n",
    "                scells = []\n",
    "            \n",
    "            if serv_freq != target_freq:\n",
    "                a,b = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 1)\n",
    "                others += \" Inter frequency HO.\"\n",
    "                if a is not None:\n",
    "                    others += \" Near after RLF.\"\n",
    "                \n",
    "            if df[\"nr-rrc.t304\"].iloc[i] == 1 and df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "                    a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 2)\n",
    "                    \n",
    "                    if a is not None:\n",
    "\n",
    "                        ho_type, ho = find_in_D_first_before(['RLF_II', 'RLF_III'], 2)\n",
    "                        others += f' Near after RLF of trans: {ho.trans}.'\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        ho_type, _ = find_in_D_first_before(['MN_HO_to_eNB', 'SN_Rel'], 2)\n",
    "                        if ho_type is not None:\n",
    "                            others += f' Near after {ho_type}.'\n",
    "\n",
    "                    ori_serv = nr_pci\n",
    "                    nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "                    trans = f'({serv_cell}, {serv_freq}) | {ori_serv} -> {nr_pci}'\n",
    "                    D['SN_setup'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "                    trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {nr_pci}'\n",
    "                    D['MN_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "            else:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "                    a, b = find_1st_before(i, \"scgFailureInformationNR-r15\")\n",
    "                    if a is not None:\n",
    "                        others += \" Caused by scg-failure.\"\n",
    "                    \n",
    "                    orig_serv = nr_pci\n",
    "                    nr_pci = 'O'\n",
    "                    trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                    D['SN_Rel'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    a, _ = find_1st_before(i,\"rrcConnectionSetup\",3)\n",
    "                    if a is not None:\n",
    "                        others += ' Near After connection setup.'\n",
    "                    if nr_pci == 'O':\n",
    "                        trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {nr_pci}'\n",
    "                        D['LTE_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "                    else:\n",
    "                        orig_serv = nr_pci\n",
    "                        nr_pci = 'O'\n",
    "                        trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                        D['MN_HO_to_eNB'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "\n",
    "        if df[\"nr-rrc.t304\"].iloc[i] == 1 and not df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "\n",
    "            end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "        \n",
    "            serv_cell, serv_freq = df[\"PCI\"].iloc[i], int(df[\"Freq\"].iloc[i])\n",
    "            orig_serv = nr_pci\n",
    "            nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "            trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "            D['SN_HO'].append(HO(start=t,end=end,trans=trans))\n",
    "\n",
    "\n",
    "        if df[\"rrcConnectionReestablishmentRequest\"].iloc[i] == 1:\n",
    "\n",
    "            end1, _ = find_1st_after(i, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "            b, _ = find_1st_after(i, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "            end2, _ = find_1st_after(i, 'securityModeComplete',look_after=3)\n",
    "\n",
    "            others += ' ' + df[\"reestablishmentCause\"].iloc[i] + '.'\n",
    "            scells = []\n",
    "\n",
    "            c, _ = find_1st_before(i, 'scgFailureInformationNR-r15', 1)\n",
    "            if c != None:\n",
    "                others  += ' caused by scgfailure.'\n",
    "                \n",
    "            serv_cell, rlf_cell = df[\"PCI\"].iloc[i], int(df['physCellId.3'].iloc[i])\n",
    "            serv_freq = int(df['Freq'].iloc[i])\n",
    "            \n",
    "            # Type II & Type III\n",
    "            if end1 is not None: \n",
    "\n",
    "                orig_serv = nr_pci\n",
    "                nr_pci = 'O'\n",
    "                _, idx = find_1st_before_with_special_value(i, 'PCI', rlf_cell, look_before=10)\n",
    "                rlf_freq = int(df['Freq'].iloc[idx])\n",
    "                trans = f'({rlf_cell}, {rlf_freq}) -> ({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                D['RLF_II'].append(HO(start=t,end=end1,others=others,trans=trans))\n",
    "\n",
    "                lte_pci = serv_cell\n",
    "                lte_earfcn = serv_freq\n",
    "\n",
    "            elif b is not None and end2 is not None:\n",
    "                \n",
    "                orig_serv = nr_pci\n",
    "                nr_pci = 'O'\n",
    "                _, idx = find_1st_before_with_special_value(i, 'PCI', rlf_cell, look_before=10)\n",
    "                rlf_freq = int(df['Freq'].iloc[idx])\n",
    "\n",
    "                _, idx = find_1st_after(i, \"rrcConnectionRequest\", 2)\n",
    "                recon_cell, recon_freq = df['PCI'].iloc[idx], int(float(df['Freq'].iloc[idx]))\n",
    "                \n",
    "                trans = f'({rlf_cell}, {rlf_freq}) -> ({recon_cell}, {recon_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                D['RLF_III'].append(HO(start=t,end=end2,others=others,trans=trans)) \n",
    "\n",
    "                # lte_pci, lte_earfcn will be updated in rrcConnectionRequest.     \n",
    "                \n",
    "            else:\n",
    "\n",
    "                others+=' No end.'\n",
    "                D['RLF_II'].append(HO(start=t,others=others))\n",
    "                print('No end for RLF')\n",
    "\n",
    "        if df[\"scgFailureInformationNR-r15\"].iloc[i] == 1:\n",
    "\n",
    "            others += ' ' + df[\"failureType-r15\"].iloc[i] + '.'\n",
    "            a, idx1 = find_1st_after(i, \"rrcConnectionReestablishmentRequest\", look_after=1)\n",
    "            b, idx2 = find_1st_after(i, \"lte-rrc.t304\", look_after=10)\n",
    "\n",
    "            if a is not None:\n",
    "\n",
    "                end1, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "                b, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "                end2 = find_1st_after(idx1, 'securityModeComplete',look_after=3)[0]\n",
    "\n",
    "                others += ' Result in rrcReestablishment.'\n",
    "                    \n",
    "                # Type II & Type III Result\n",
    "                if end1 is not None: \n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end1,others=others))\n",
    "                elif b is not None and end2 is not None: \n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end2,others=others))\n",
    "                else:\n",
    "                    others += ' No end.'\n",
    "                    D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "                    print('No end for scg failure result in rrcReestablishment.')\n",
    "\n",
    "            elif b is not None:\n",
    "\n",
    "                end, _ = find_1st_after(idx2, 'rrcConnectionReconfigurationComplete')\n",
    "                serv_cell, target_cell = df[\"PCI\"].iloc[idx2], df['lte_targetPhysCellId'].iloc[idx2]\n",
    "                serv_freq, target_freq = int(df[\"Freq\"].iloc[idx2]), df['dl-CarrierFreq'].iloc[idx2]\n",
    "                # We do not change nr_pci here. Instead, we will change it at gNB_Rel event.\n",
    "                trans = f'({serv_cell}, {serv_freq}) | {nr_pci} -> O'\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "                    others += ' Result in gNB release.'\n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end,others=others,trans=trans))\n",
    "                else:\n",
    "                    others += ' Result in MN HO to eNB.'\n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end,others=others,trans=trans))                  \n",
    "\n",
    "            else:\n",
    "\n",
    "                print('No end for scg failure.')\n",
    "                others += ' No end.'\n",
    "                D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "        \n",
    "        if df['SCellToAddMod-r10'].iloc[i] == 1 and df['physCellId-r10'].iloc[i] != 'nr or cqi report':\n",
    "\n",
    "            others = ''\n",
    "            pcis = str(df[\"physCellId-r10\"].iloc[i]).split('@')\n",
    "            freqs = str(df[\"dl-CarrierFreq-r10\"].iloc[i]).split('@')\n",
    "            orig_scells = scells\n",
    "            scells = [(int(float(pci)), int(float(freq))) for pci, freq in zip(pcis, freqs)]\n",
    "\n",
    "            others += f' Set up {len(scells)} SCell.'\n",
    "            trans = f'{orig_scells} -> {scells}'\n",
    "\n",
    "            end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "            \n",
    "            a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 3)\n",
    "            if a is not None:\n",
    "                others += ' Near after RLF.'\n",
    "\n",
    "            a = find_in_D_exact(['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel'])\n",
    "            if a is not None:\n",
    "                others += f' With {a}.'\n",
    "\n",
    "            D['Add_SCell'].append(HO(start=t,end=end,others=others, trans=trans))\n",
    "    \n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistic functions\n",
    "# This function input the file path of the loss_latency csv and output the loss and excessive latency rate.\n",
    "def count_loss_excl_rate(file_path):\n",
    "\n",
    "    df = pd.read_csv (file_path)\n",
    "\n",
    "    # Total package in the experiment\n",
    "    total_pkg_num = len(df)\n",
    "\n",
    "    # Loss calculate\n",
    "    loss_cond = df['lost'] == True\n",
    "    try: loss_num = loss_cond.value_counts().loc[True]\n",
    "    except: loss_num = 0\n",
    "    loss_rate = loss_num/total_pkg_num\n",
    "\n",
    "    # Excexxive latency calculate\n",
    "    exc_lat = 0.1\n",
    "    excl_cond = df[loss_cond==False]['latency'] > exc_lat\n",
    "    try: excl_num = excl_cond.value_counts().loc[True]\n",
    "    except: excl_num = 0\n",
    "    excl_rate = excl_num/total_pkg_num\n",
    "\n",
    "    return loss_rate, excl_rate\n",
    "\n",
    "# This function input two file paths of the loss_latency csv and output the \n",
    "# loss and excessive latency rate of dual radio condition.\n",
    "def count_loss_excl_rate_dual(file_path1, file_path2):\n",
    "\n",
    "    df1 = pd.read_csv(file_path1)\n",
    "    df2 = pd.read_csv(file_path2)\n",
    "\n",
    "    start_seq = df1['seq'].iloc[0] if df1['seq'].iloc[0] >=  df2['seq'].iloc[0] else df2['seq'].iloc[0]\n",
    "    end_seq = df1['seq'].iloc[-1] if df1['seq'].iloc[-1] <=  df2['seq'].iloc[-1] else df2['seq'].iloc[-1]\n",
    "    total_pkg_num = end_seq - start_seq + 1\n",
    "\n",
    "    cond1 = (df1['seq'] >= start_seq) & (df1['seq'] <= end_seq)\n",
    "    df1 = df1[cond1]\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    cond2 = (df2['seq'] >= start_seq) & (df2['seq'] <= end_seq)\n",
    "    df2 = df2[cond2]\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "\n",
    "    # Loss calculate for dual radios redundant packets.\n",
    "    loss_cond = (df1['lost'] == True) & (df2['lost'] == True)\n",
    "    try: loss_num = loss_cond.value_counts().loc[True]\n",
    "    except: loss_num = 0\n",
    "    loss_rate = loss_num/total_pkg_num\n",
    "\n",
    "    # Excexxive latency calculate for dual radios redundant packets.\n",
    "    exc_lat = 0.1   \n",
    "    excl_cond1 = df1[(loss_cond==False)]['latency'] > exc_lat\n",
    "    excl_cond2 = df2[(loss_cond==False)]['latency'] > exc_lat\n",
    "    excl_cond = (excl_cond1 == True) & (excl_cond2 == True)\n",
    "    try: excl_num = excl_cond.value_counts().loc[True]\n",
    "    except: excl_num = 0\n",
    "    excl_rate = excl_num/total_pkg_num\n",
    "\n",
    "    return loss_rate, excl_rate\n",
    "\n",
    "# This function input two file paths of the loss_latency csv and output the \n",
    "# loss and excessive latency rate of dual radio condition.\n",
    "def count_loss_excl_rate_dual(file_path1, file_path2):\n",
    "\n",
    "    df1 = pd.read_csv(file_path1)\n",
    "    df2 = pd.read_csv(file_path2)\n",
    "\n",
    "    start_seq = df1['seq'].iloc[0] if df1['seq'].iloc[0] >=  df2['seq'].iloc[0] else df2['seq'].iloc[0]\n",
    "    end_seq = df1['seq'].iloc[-1] if df1['seq'].iloc[-1] <=  df2['seq'].iloc[-1] else df2['seq'].iloc[-1]\n",
    "    total_pkg_num = end_seq - start_seq + 1\n",
    "\n",
    "    cond1 = (df1['seq'] >= start_seq) & (df1['seq'] <= end_seq)\n",
    "    df1 = df1[cond1]\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    cond2 = (df2['seq'] >= start_seq) & (df2['seq'] <= end_seq)\n",
    "    df2 = df2[cond2]\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "\n",
    "    # Loss calculate for dual radios redundant packets.\n",
    "    loss_cond = (df1['lost'] == True) & (df2['lost'] == True)\n",
    "    try: loss_num = loss_cond.value_counts().loc[True]\n",
    "    except: loss_num = 0\n",
    "    loss_rate = loss_num/total_pkg_num\n",
    "\n",
    "    # Excexxive latency calculate for dual radios redundant packets.\n",
    "    exc_lat = 0.1   \n",
    "    excl_cond1 = df1[(loss_cond==False)]['latency'] > exc_lat\n",
    "    excl_cond2 = df2[(loss_cond==False)]['latency'] > exc_lat\n",
    "    excl_cond = (excl_cond1 == True) & (excl_cond2 == True)\n",
    "    try: excl_num = excl_cond.value_counts().loc[True]\n",
    "    except: excl_num = 0\n",
    "    excl_rate = excl_num/total_pkg_num\n",
    "\n",
    "    return loss_rate, excl_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This place give a XXXX-XX-XX.md file and find the experiment directory path\n",
    "# and the corresponding band settings. It will be presented by a list of special\n",
    "# instance EXPERIMENTs.\n",
    "md_files = ['/home/wmnlab/D/database/2023-08-29/2023-08-29.md', \n",
    "            '/home/wmnlab/D/database/2023-09-12_1/2023-09-12.md',\n",
    "            '/home/wmnlab/D/database/2023-09-22/2023-09-22.md',\n",
    "            '/home/wmnlab/D/database/2023-10-24/2023-10-24.md']\n",
    "EXPs = []\n",
    "\n",
    "for md_file_path in md_files:\n",
    "\n",
    "    date_dir_path = os.path.dirname(md_file_path)\n",
    "\n",
    "    with open(md_file_path) as f:\n",
    "\n",
    "        exp = f.readline()[:-1]\n",
    "        settings = f.readline()[:-1]\n",
    "\n",
    "        while exp != '#endif' and settings:\n",
    "            E = EXPERIMENT(os.path.join(date_dir_path, exp), settings)\n",
    "            EXPs.append(E)\n",
    "            exp = f.readline()[:-1]\n",
    "            settings = f.readline()[:-1]\n",
    "\n",
    "pprint(EXPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss/Excl Lat  Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Radio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the example of given a experiment directory and plot the \n",
    "# box plot of DL/UL loss/excessive latency. \n",
    "\n",
    "# Still need to revise here.\n",
    "\n",
    "dev_metric_dicts = []\n",
    "\n",
    "for EXP in EXPs:\n",
    "\n",
    "    dev_metric_dict = {}    \n",
    "    exp_dir_path = EXP.path\n",
    "    settings = EXP.settings \n",
    "\n",
    "    dev_dir_list = find_device_under_exp(exp_dir_path)\n",
    "\n",
    "    for dev_dir_path in dev_dir_list:\n",
    "\n",
    "        dev = dev_dir_path.split('/')[-1]\n",
    "        metrics_dict = {}\n",
    "        trace_dir_list = find_trace_under_device(dev_dir_path)\n",
    "        dl_loss_rates, dl_excl_rates = [], []    \n",
    "        ul_loss_rates, ul_excl_rates = [], []\n",
    "\n",
    "        for trace_dir_path in trace_dir_list:\n",
    "\n",
    "            # if '#01' not in trace_dir_path:\n",
    "            #     continue\n",
    "\n",
    "            dl_file_path = os.path.join(trace_dir_path, 'data/udp_dnlk_loss_latency.csv')\n",
    "            ul_file_path = os.path.join(trace_dir_path, 'data/udp_uplk_loss_latency.csv')\n",
    "\n",
    "            dl_loss_rate, dl_excl_rate = count_loss_excl_rate(dl_file_path)\n",
    "            ul_loss_rate, ul_excl_rate = count_loss_excl_rate(ul_file_path)\n",
    "\n",
    "            dl_loss_rates.append(dl_loss_rate); dl_excl_rates.append(dl_excl_rate)\n",
    "            ul_loss_rates.append(ul_loss_rate); ul_excl_rates.append(ul_excl_rate)\n",
    "        \n",
    "        metrics_dict['dl_loss'] = dl_loss_rates\n",
    "        metrics_dict['dl_excl'] = dl_excl_rates\n",
    "        metrics_dict['ul_loss'] = ul_loss_rates\n",
    "        metrics_dict['ul_excl'] = ul_excl_rates\n",
    "\n",
    "        dev_metric_dict[dev + ' ' + settings[dev]] = metrics_dict\n",
    "\n",
    "    dev_metric_dicts.append(dev_metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "settings = ['qc00 test', 'qc03 test', 'qc00 All', 'qc03 All']\n",
    "empty_dict = {'dl_loss': [],'dl_excl': [],'ul_loss': [], 'ul_excl': []}\n",
    "all_dev_metric_dict = {k: copy.deepcopy(empty_dict) for k in ['qc00 test', 'qc03 test', 'qc00 All', 'qc03 All']}\n",
    "\n",
    "for d in dev_metric_dicts:\n",
    "    for device in d:\n",
    "        for metric in d[device]:\n",
    "            all_dev_metric_dict[device][metric] += d[device][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dev_metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_metric_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ 'DBS\\nradio1', 'DBS\\nradio2', '5G+5G\\nradio1', '5G+5G\\nradio2']\n",
    "dl_loss_boxes, dl_excl_boxes = [], []\n",
    "ul_loss_boxes, ul_excl_boxes = [], []\n",
    "\n",
    "fig, axes = plt.subplots(2,2)\n",
    "\n",
    "# i = 0\n",
    "# for d in dev_metric_dicts:\n",
    "    \n",
    "#     for k, v in d.items():\n",
    "\n",
    "#         dl_loss_box = [value*100 for value in d[k]['dl_loss'] ] \n",
    "#         dl_excl_box = [value*100 for value in d[k]['dl_excl'] ] \n",
    "#         ul_loss_box = [value*100 for value in d[k]['ul_loss'] ]\n",
    "#         ul_excl_box = [value*100 for value in d[k]['ul_excl'] ]\n",
    "\n",
    "#         dl_loss_boxes.append(dl_loss_box)\n",
    "#         dl_excl_boxes.append(dl_excl_box)\n",
    "#         ul_loss_boxes.append(ul_loss_box)\n",
    "#         ul_excl_boxes.append(ul_excl_box)\n",
    "        \n",
    "#         i += 1\n",
    "\n",
    "for k, v in all_dev_metric_dict.items():\n",
    "\n",
    "    dl_loss_box = [value*100 for value in all_dev_metric_dict[k]['dl_loss'] ] \n",
    "    dl_excl_box = [value*100 for value in all_dev_metric_dict[k]['dl_excl'] ] \n",
    "    ul_loss_box = [value*100 for value in all_dev_metric_dict[k]['ul_loss'] ]\n",
    "    ul_excl_box = [value*100 for value in all_dev_metric_dict[k]['ul_excl'] ]\n",
    "\n",
    "    dl_loss_boxes.append(dl_loss_box)\n",
    "    dl_excl_boxes.append(dl_excl_box)\n",
    "    ul_loss_boxes.append(ul_loss_box)\n",
    "    ul_excl_boxes.append(ul_excl_box)\n",
    "\n",
    "\n",
    "axes[0][0].boxplot(dl_loss_boxes, labels=labels)\n",
    "axes[0][0].set_title('DL Loss')\n",
    "axes[0][1].boxplot(dl_excl_boxes, labels=labels)\n",
    "axes[0][1].set_title('DL Excessive Latency')\n",
    "axes[1][0].boxplot(ul_loss_boxes, labels=labels)\n",
    "axes[1][0].set_title('UL Loss')\n",
    "axes[1][1].boxplot(ul_excl_boxes, labels=labels)\n",
    "axes[1][1].set_title('UL Excessive Latency')\n",
    "\n",
    "fig.text(0.0, 0.5, 'Percentage %', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change Here\n",
    "# num = 0\n",
    "# dev_metric_dict = dev_metric_dicts[num]\n",
    "# settings = EXPs[num].settings\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(2,2)\n",
    "# dl_loss_boxes, dl_excl_boxes = [], []\n",
    "# ul_loss_boxes, ul_excl_boxes = [], []\n",
    "# labels = [settings[k] for k in list(dev_metric_dict.keys())]\n",
    "\n",
    "# for k, v in dev_metric_dict.items():\n",
    "\n",
    "#     dl_loss_box = [value*100 for value in dev_metric_dict[k]['dl_loss'] ] \n",
    "#     dl_excl_box = [value*100 for value in dev_metric_dict[k]['dl_excl'] ] \n",
    "#     ul_loss_box = [value*100 for value in dev_metric_dict[k]['ul_loss'] ]\n",
    "#     ul_excl_box = [value*100 for value in dev_metric_dict[k]['ul_excl'] ]\n",
    "\n",
    "#     dl_loss_boxes.append(dl_loss_box)\n",
    "#     dl_excl_boxes.append(dl_excl_box)\n",
    "#     ul_loss_boxes.append(ul_loss_box)\n",
    "#     ul_excl_boxes.append(ul_excl_box)\n",
    "\n",
    "# axes[0][0].boxplot(dl_loss_boxes, labels=labels)\n",
    "# axes[0][0].set_title('DL Loss')\n",
    "# axes[0][1].boxplot(dl_excl_boxes, labels=labels)\n",
    "# axes[0][1].set_title('DL Excessive Latency')\n",
    "# axes[1][0].boxplot(ul_loss_boxes, labels=labels)\n",
    "# axes[1][0].set_title('UL Loss')\n",
    "# axes[1][1].boxplot(ul_excl_boxes, labels=labels)\n",
    "# axes[1][1].set_title('UL Excessive Latency')\n",
    "\n",
    "# # fig.text(0.5, 0.0, 'common xlabel', ha='center', va='center', fontsize=16)\n",
    "# fig.text(0.0, 0.5, 'Percentage %', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual Radio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This place calculate the dual redio performance \n",
    "# given a experiment directory.\n",
    "\n",
    "# Still need to revise here.\n",
    "\n",
    "comb_metric_dicts = []\n",
    "corresponding_list = []\n",
    "\n",
    "for EXP in EXPs:\n",
    "\n",
    "    exp_dir_path = EXP.path\n",
    "    settings = EXP.settings \n",
    "\n",
    "    dev_dir_list = find_device_under_exp(exp_dir_path)\n",
    "    comb = itertools.combinations(dev_dir_list, 2)\n",
    "\n",
    "    date = exp_dir_path.split('/')[-2]\n",
    "    name = exp_dir_path.split('/')[-1]\n",
    "    \n",
    "    for dev_dir_path1, dev_dir_path2 in comb:\n",
    "        \n",
    "        dev1 = dev_dir_path1.split('/')[-1]\n",
    "        dev2 = dev_dir_path2.split('/')[-1]\n",
    "\n",
    "        trace_dir_list1 = find_trace_under_device(dev_dir_path1)\n",
    "        trace_dir_list2 = find_trace_under_device(dev_dir_path2)\n",
    "        \n",
    "        for trace_dir_path1, trace_dir_path2 in zip(trace_dir_list1, trace_dir_list2):\n",
    "            \n",
    "            # Record\n",
    "            trace = trace_dir_path1.split('/')[-1]\n",
    "            print(date, name, dev1, dev2, trace)\n",
    "            corresponding_list.append((date, name, dev1, dev2, trace))\n",
    "            \n",
    "            dl_file_path1 = os.path.join(trace_dir_path1, 'data/udp_dnlk_loss_latency.csv')\n",
    "            ul_file_path1 = os.path.join(trace_dir_path1, 'data/udp_uplk_loss_latency.csv')\n",
    "            dl_file_path2 = os.path.join(trace_dir_path2, 'data/udp_dnlk_loss_latency.csv')\n",
    "            ul_file_path2 = os.path.join(trace_dir_path2, 'data/udp_uplk_loss_latency.csv')\n",
    "\n",
    "            dl_loss_rate, dl_excl_rate = count_loss_excl_rate_dual(dl_file_path1, dl_file_path2)\n",
    "            ul_loss_rate, ul_excl_rate = count_loss_excl_rate_dual(ul_file_path1, ul_file_path2)\n",
    "\n",
    "            metrics_dict = {}\n",
    "            metrics_dict['dl_loss'] = dl_loss_rate\n",
    "            metrics_dict['dl_excl'] = dl_excl_rate\n",
    "            metrics_dict['ul_loss'] = ul_loss_rate\n",
    "            metrics_dict['ul_excl'] = ul_excl_rate\n",
    "\n",
    "            comb_metric_dicts.append(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_metric_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corresponding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_group = {}\n",
    "control_group = {} # All + All\n",
    "control_group2 = {} # All + LTE\n",
    "control_group3 = {} # Lock band + Lock band\n",
    "\n",
    "keys = ['dl_loss', 'dl_excl', 'ul_loss', 'ul_excl']\n",
    "\n",
    "for k in keys:\n",
    "    action_group[k] = []\n",
    "    control_group[k] = []\n",
    "    control_group2[k] = []\n",
    "    control_group3[k] = []\n",
    "\n",
    "for comb_metric_dict, info in zip(comb_metric_dicts, corresponding_list):\n",
    "\n",
    "    name = info[1]\n",
    "    \n",
    "    for k, v in comb_metric_dict.items():\n",
    "\n",
    "        if name == 'Modem_Action_Test':\n",
    "            action_group[k].append(v)\n",
    "        elif name == 'Modem_Control_Group':\n",
    "            control_group[k].append(v)\n",
    "        elif name == 'Modem_Control_Group2':\n",
    "            control_group2[k].append(v)\n",
    "        elif name == 'Modem_Control_Group3':\n",
    "            control_group3[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control_group2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of performance.\n",
    "fig, axes = plt.subplots(2,2)\n",
    "dl_loss_boxes, dl_excl_boxes = [], []\n",
    "ul_loss_boxes, ul_excl_boxes = [], []\n",
    "labels = ['DBL', '5G+5G', '5g+LTE', ' B1B3+B7B8']\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "for d in [action_group, control_group, control_group2, control_group3]:\n",
    "\n",
    "    dl_loss_box = [value*100 for value in d['dl_loss'] ] \n",
    "    dl_excl_box = [value*100 for value in d['dl_excl'] ] \n",
    "    ul_loss_box = [value*100 for value in d['ul_loss'] ]\n",
    "    ul_excl_box = [value*100 for value in d['ul_excl'] ]\n",
    "\n",
    "    dl_loss_boxes.append(dl_loss_box)\n",
    "    dl_excl_boxes.append(dl_excl_box)\n",
    "    ul_loss_boxes.append(ul_loss_box)\n",
    "    ul_excl_boxes.append(ul_excl_box)\n",
    "\n",
    "# A useful one.\n",
    "def int_to_bin(x):\n",
    "    x = bin(x)\n",
    "    if len(x) < 4:\n",
    "        x = x[:2] + '0' + x[2:]\n",
    "    return x[2:]\n",
    "\n",
    "titles = ['DL Loss', 'DL Excessive Latency', 'UL Loss', 'UL Excessive Latency']\n",
    "\n",
    "for i, target in enumerate([dl_loss_boxes, dl_excl_boxes, ul_loss_boxes, ul_excl_boxes]):\n",
    "\n",
    "    s = int_to_bin(i)\n",
    "    n1, n2 = int(s[0]), int(s[1])\n",
    "\n",
    "    data = {k:v for k, v in zip(labels, target)}\n",
    "    sns.boxplot(data=list(data.values()), showmeans=True, ax=axes[n1, n2]) \n",
    "    axes[n1][n2].set_title(titles[i])\n",
    "    axes[n1,n2].set_xticks(list(range(len(labels))))\n",
    "    axes[n1][n2].set_xticklabels(labels)\n",
    "\n",
    "    # Textx the value of mean.\n",
    "    for j, group_name in enumerate(data.keys()):\n",
    "        mean_value = sum(data[group_name])/len(data[group_name])\n",
    "        axes[n1, n2].text(j, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=12, color='red')\n",
    "\n",
    "# fig.text(0.5, 0.0, 'common xlabel', ha='center', va='center', fontsize=16)\n",
    "fig.text(0.0, 0.5, 'Percentage %', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb_metric_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_dict = {'dl_loss': [],'dl_excl': [],'ul_loss': [], 'ul_excl': []}\n",
    "all_comb_metric_dict = {k: copy.deepcopy(empty_dict) for k in comb_metric_dicts[0].keys()}\n",
    "\n",
    "for d in comb_metric_dicts:\n",
    "    for device in d:\n",
    "        for metric in d[device]:\n",
    "            all_comb_metric_dict[device][metric] += d[device][metric]\n",
    "            \n",
    "# all_comb_metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This place calculate the average performance of an \n",
    "# experiment setting and plot the heatmap below.\n",
    " \n",
    "num = 0\n",
    "comb_metric_dict = comb_metric_dicts[num]\n",
    "settings = EXPs[num].settings\n",
    "\n",
    "# num_of_devs = 2\n",
    "num_of_devs = len(settings)\n",
    "data_dl_loss = np.zeros((num_of_devs, num_of_devs))\n",
    "data_dl_excl = np.zeros((num_of_devs, num_of_devs))\n",
    "data_ul_loss = np.zeros((num_of_devs, num_of_devs))\n",
    "data_ul_excl = np.zeros((num_of_devs, num_of_devs))\n",
    "\n",
    "keys = list(comb_metric_dict.keys())\n",
    "count = 0\n",
    "\n",
    "for i in range(num_of_devs):\n",
    "    for j in range(i+1, num_of_devs):\n",
    "\n",
    "        k = keys[count]\n",
    "        \n",
    "        dl_loss = np.mean(comb_metric_dict[k]['dl_loss'])\n",
    "        dl_excl = np.mean(comb_metric_dict[k]['dl_excl'])\n",
    "        ul_loss = np.mean(comb_metric_dict[k]['ul_loss'])\n",
    "        ul_excl = np.mean(comb_metric_dict[k]['ul_excl'])\n",
    "\n",
    "        data_dl_loss[i, j] = dl_loss*100\n",
    "        data_dl_excl[i, j] = dl_excl*100\n",
    "        data_ul_loss[i, j] = ul_loss*100\n",
    "        data_ul_excl[i, j] = ul_excl*100\n",
    "\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(8,6))\n",
    "\n",
    "# labels = ['378', '3']\n",
    "labels = list(settings.values())\n",
    "mask = np.tri(data_dl_loss.shape[0], dtype=bool, k=0)\n",
    "\n",
    "sns.heatmap(data_dl_loss, ax=axes[0,0], mask=mask, annot=True, fmt=\".2f\")\n",
    "axes[0,0].set_xticklabels(labels, rotation=90)\n",
    "axes[0,0].set_yticklabels(labels, rotation=0)\n",
    "axes[0,0].set_title('DL Loss')\n",
    "sns.heatmap(data_dl_excl, ax=axes[0,1], mask=mask, annot=True, fmt=\".2f\")\n",
    "axes[0,1].set_xticklabels(labels, rotation=90)\n",
    "axes[0,1].set_yticklabels(labels, rotation=0)\n",
    "axes[0,1].set_title('DL Excessive Latency')\n",
    "sns.heatmap(data_ul_loss, ax=axes[1,0], mask=mask, annot=True, fmt=\".2f\")\n",
    "axes[1,0].set_xticklabels(labels, rotation=90)\n",
    "axes[1,0].set_yticklabels(labels, rotation=0)\n",
    "axes[1,0].set_title('UL Loss')\n",
    "sns.heatmap(data_ul_excl, ax=axes[1,1], mask=mask, annot=True, fmt=\".2f\")\n",
    "axes[1,1].set_xticklabels(labels, rotation=90)\n",
    "axes[1,1].set_yticklabels(labels, rotation=0)\n",
    "axes[1,1].set_title('UL Excessive Latency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dl_loss, dl_excl, ul_loss, ul_excl <br>\n",
    "0.00, 0.07, 0.02, 0.82 -- Modem action <br>\n",
    "0.33, 0.08, 0.10, 0.46 -- Modem Control "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This place take off the HO closeness of dual radio system.\n",
    "counts = []\n",
    "corresponding_list = []\n",
    "\n",
    "for EXP in EXPs:\n",
    "\n",
    "    exp_dir_path = EXP.path\n",
    "    settings = EXP.settings \n",
    "\n",
    "    dev_dir_list = find_device_under_exp(exp_dir_path)\n",
    "    comb = itertools.combinations(dev_dir_list, 2)\n",
    "\n",
    "    date = exp_dir_path.split('/')[-2]\n",
    "    name = exp_dir_path.split('/')[-1]\n",
    "    \n",
    "    for dev_dir_path1, dev_dir_path2 in comb:\n",
    "        \n",
    "        dev1 = dev_dir_path1.split('/')[-1]\n",
    "        dev2 = dev_dir_path2.split('/')[-1]\n",
    "\n",
    "        trace_dir_list1 = find_trace_under_device(dev_dir_path1)\n",
    "        trace_dir_list2 = find_trace_under_device(dev_dir_path2)\n",
    "        \n",
    "        for trace_dir_path1, trace_dir_path2 in zip(trace_dir_list1, trace_dir_list2):\n",
    "            \n",
    "            # Record\n",
    "            trace = trace_dir_path1.split('/')[-1]\n",
    "            print(date, name, dev1, dev2, trace)\n",
    "            corresponding_list.append((date, name, dev1, dev2, trace))\n",
    "        \n",
    "            rrc_file_path1 = os.path.join(trace_dir_path1, 'data')\n",
    "            rrc_file1 = [os.path.join(rrc_file_path1, s) for s in os.listdir(rrc_file_path1) if s.endswith('_rrc.csv')][0]    \n",
    "            rrc_file_path2 = os.path.join(trace_dir_path2, 'data')\n",
    "            rrc_file2 = [os.path.join(rrc_file_path2, s) for s in os.listdir(rrc_file_path2) if s.endswith('_rrc.csv')][0]\n",
    "\n",
    "            hos1 = parse_mi_ho(rrc_file1)\n",
    "            hos2 = parse_mi_ho(rrc_file2)\n",
    "\n",
    "            # Check if there exist too close RLF of two radios.\n",
    "            events = ['RLF+RLF', 'RLF+Conn Req']\n",
    "            count = {k:0 for k in events}\n",
    "            \n",
    "            for a in (hos1['RLF_II'] + hos1['RLF_III']):\n",
    "                for b in (hos2['RLF_II'] + hos2['RLF_III']):\n",
    "                    if abs((a.start - b.start).total_seconds() ) < 2:\n",
    "                        count['RLF+RLF'] += 1\n",
    "\n",
    "            for a in (hos1['RLF_II'] + hos1['RLF_III']):\n",
    "                for b in hos2['Conn_Req']:\n",
    "                    if abs((a.start - b.start).total_seconds() ) < 2:\n",
    "                        count['RLF+Conn Req'] += 1\n",
    "\n",
    "            counts.append(count)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_group = {k:0 for k in events}\n",
    "control_group = {k:0 for k in events} # All + All\n",
    "control_group2 = {k:0 for k in events} # All + LTE\n",
    "control_group3 = {k:0 for k in events} # Lock Band+Lock Band\n",
    "\n",
    "for d, info in zip(counts, corresponding_list):\n",
    "\n",
    "    name = info[1]    \n",
    "\n",
    "    for k, v in d.items():\n",
    "        if name == 'Modem_Action_Test':\n",
    "            action_group[k] += v\n",
    "        elif name == 'Modem_Control_Group':\n",
    "            control_group[k] += v\n",
    "        elif name == 'Modem_Control_Group2':\n",
    "            control_group2[k] += v\n",
    "        elif name == 'Modem_Control_Group3':\n",
    "            control_group3[k] += v\n",
    "\n",
    "action_group, control_group, control_group2, control_group3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2, n3, n4 = 9, 10, 10, 6\n",
    "\n",
    "sns.set(style='white')\n",
    "\n",
    "# 示例数据\n",
    "categories = ['DBL', '5G+5G', '5G+LTE', 'B1B3+B7B8']\n",
    "values = [action_group['RLF+RLF']/n1, control_group['RLF+RLF']/n2, control_group2['RLF+RLF']/n3, control_group3['RLF+RLF']/n4]\n",
    "values2 = [action_group['RLF+Conn Req']/n1, control_group['RLF+Conn Req']/n2, control_group2['RLF+Conn Req']/n3, control_group3['RLF+Conn Req']/n4]\n",
    "\n",
    "\n",
    "width = 0.3\n",
    "x = list(range(len(categories)))\n",
    "x1 = [a-width/2 for a in x]\n",
    "x2 = [a+width/2 for a in x]\n",
    "\n",
    "D = {}\n",
    "for i in range(len(categories)):\n",
    "    D[categories[i]] = []\n",
    "\n",
    "# 示例数据\n",
    "data = []\n",
    "\n",
    "# 使用for循环生成数据\n",
    "for i in range(len(categories)):\n",
    "    name = categories[i]\n",
    "    value1 = values[i]\n",
    "    value2 = values2[i]\n",
    "    data.append({'Scheme': name, 'Average Times': values[i], 'Type': 'RLF+RLF'})\n",
    "    data.append({'Scheme': name, 'Average Times': values2[i], 'Type': 'RLF+Conn Req'})\n",
    "\n",
    "# 将数据转换为Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "sns.barplot(x='Scheme', y='Average Times', hue='Type', data=df, palette='rocket')\n",
    "\n",
    "# plt.title('')  # 图表标题\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrc_files = []\n",
    "\n",
    "for EXP in EXPs:\n",
    "\n",
    "    dev_metric_dict = {}    \n",
    "    exp_dir_path = EXP.path\n",
    "    settings = EXP.settings \n",
    "\n",
    "    dev_dir_list = find_device_under_exp(exp_dir_path)\n",
    "\n",
    "    record_dict = {k: [] for k in settings.keys()}\n",
    "\n",
    "    for dev_dir_path in dev_dir_list:\n",
    "\n",
    "        dev = dev_dir_path.split('/')[-1]\n",
    "\n",
    "        trace_dir_list = find_trace_under_device(dev_dir_path)\n",
    "        \n",
    "        for trace_dir_path in trace_dir_list:\n",
    "\n",
    "            rrc_file_path = os.path.join(trace_dir_path, 'data')\n",
    "            rrc_file = [os.path.join(rrc_file_path, s) for s in os.listdir(rrc_file_path) if s.endswith('_rrc.csv')][0]\n",
    "            \n",
    "            record_dict[dev].append(rrc_file)\n",
    "\n",
    "\n",
    "    rrc_files.append(record_dict)\n",
    "\n",
    "pprint(EXPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['Conn_Req', 'LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF']\n",
    "total1 = {type: 0 for type in types} # Test Radio1\n",
    "total2 = {type: 0 for type in types} # Test Radio2\n",
    "total3 = {type: 0 for type in types} # 5G Radio1\n",
    "total4 = {type: 0 for type in types} # 5G Radio2\n",
    "\n",
    "for rrc_file in rrc_files:\n",
    "\n",
    "    f1s = rrc_file['qc00']\n",
    "    f2s = rrc_file['qc03']\n",
    "\n",
    "    for i, (f1, f2) in enumerate(zip(f1s, f2s)):\n",
    "\n",
    "        hos1 = parse_mi_ho(f1)\n",
    "        t1 = {k:len(v) for k, v in hos1.items()}\n",
    "        \n",
    "        print(f1, t1)\n",
    "\n",
    "        for type in types:\n",
    "            if 'Modem_Action_Test' in f1:\n",
    "                total1[type] += t1[type]\n",
    "            elif 'Modem_Control_Group' in f1:\n",
    "                total3[type] += t1[type]\n",
    "\n",
    "        hos2 = parse_mi_ho(f2)\n",
    "        t2 = {k:len(v) for k, v in hos2.items()}\n",
    "        for type in types:\n",
    "            if 'Modem_Action_Test' in f2:\n",
    "                total2[type] += t2[type]\n",
    "            elif 'Modem_Control_Group' in f2:\n",
    "                total4[type] += t2[type]\n",
    "\n",
    "        print(f2, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2 = 9, 10\n",
    "total1 = {k:round(v/n1, 2) for k, v in total1.items()}\n",
    "total2 = {k:round(v/n1, 2) for k, v in total2.items()}\n",
    "total3 = {k:round(v/n2, 2) for k, v in total3.items()}\n",
    "total4 = {k:round(v/n2, 2) for k, v in total4.items()}\n",
    "total1, total2, total3, total4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict = rrc_files[1]\n",
    "keys = list(record_dict.keys())\n",
    "values = list(record_dict.values())\n",
    "\n",
    "dev1, rrc_file_list1 = keys[0], values[0]\n",
    "dev2, rrc_file_list2 = keys[1], values[1]\n",
    "\n",
    "for file1, file2 in zip(rrc_file_list1, rrc_file_list2):\n",
    "\n",
    "    HOs1 = parse_mi_ho(file1)\n",
    "    ordered_HOs1 = print_trans(HOs1, p=False)\n",
    "    HOs2 = parse_mi_ho(file2)\n",
    "    ordered_HOs2 = print_trans(HOs2, p=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "\n",
    "for ho in ordered_HOs1:\n",
    "\n",
    "    \n",
    "    write_list = [ho[1].start, ho[0], ho[1].trans, ho[1].others, 1]\n",
    "    L.append(write_list)\n",
    "    write_list = [str(s) for s in write_list]\n",
    "\n",
    "for ho in ordered_HOs2:\n",
    "\n",
    "    write_list = [ho[1].start, ho[0], ho[1].trans, ho[1].others, 2]\n",
    "    L.append(write_list)\n",
    "    write_list = [str(s) for s in write_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/wmnlab/sheng-ru/HO_compare.csv'\n",
    "\n",
    "with open(save_path, 'w') as f:\n",
    "\n",
    "    f.write('@'.join(['timestamp', 'type', 'trans', 'others', 'num']) + '\\n')\n",
    "\n",
    "    for l in sorted(L, key = lambda x: x[0]):\n",
    "\n",
    "        write_list = l\n",
    "        write_list = [str(s) for s in write_list]\n",
    "        f.write('@'.join(write_list) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This place give a XXXX-XX-XX.md file and find the experiment directory path\n",
    "# and the corresponding band settings. It will be presented by a list of special\n",
    "# instance EXPERIMENTs.\n",
    "md_files = ['/home/wmnlab/D/database/2023-06-24/2023-06-24.md']\n",
    "EXPs = []\n",
    "\n",
    "for md_file_path in md_files:\n",
    "\n",
    "    date_dir_path = os.path.dirname(md_file_path)\n",
    "\n",
    "    with open(md_file_path) as f:\n",
    "\n",
    "        exp = f.readline()[:-1]\n",
    "        settings = f.readline()[:-1]\n",
    "\n",
    "        while exp != '#endif' and settings:\n",
    "            E = EXPERIMENT(os.path.join(date_dir_path, exp), settings)\n",
    "            EXPs.append(E)\n",
    "            exp = f.readline()[:-1]\n",
    "            settings = f.readline()[:-1]\n",
    "\n",
    "pprint(EXPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for EXP in EXPs:\n",
    "\n",
    "#     exp_dir_path = EXP.path\n",
    "#     settings = EXP.settings \n",
    "\n",
    "#     dev_dir_list = find_device_under_exp(exp_dir_path)\n",
    "\n",
    "#     date = exp_dir_path.split('/')[-2]\n",
    "#     name = exp_dir_path.split('/')[-1]\n",
    "    \n",
    "\n",
    "#     for dev_dir_path in dev_dir_list:    \n",
    "    \n",
    "#         dev = dev_dir_path.split('/')[-1]\n",
    "        \n",
    "#         trace_dir_list = find_trace_under_device(dev_dir_path)\n",
    "\n",
    "#         for trace_dir_path in trace_dir_list:\n",
    "\n",
    "#             trace = trace_dir_path1.split('/')[-1]\n",
    "\n",
    "#             data_dir_path = os.path.join(trace_dir_path, 'data')\n",
    "#             rrc_file = [p for p in os.listdir(data_dir_path) if p.endswith('_rrc.csv')][0]\n",
    "#             rrc_file_path = os.path.join(data_dir_path, rrc_file)\n",
    "            \n",
    "\n",
    "#             print(rrc_file_path)\n",
    "#             HOs = parse_mi_ho(rrc_file_path)\n",
    "#             if len(HOs['RLF_III']) != 0:\n",
    "#                 raise\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
